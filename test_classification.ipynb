{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from neural_networks import NeuralNetwork as NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>...</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>conditions</th>\n",
       "      <th>stations</th>\n",
       "      <th>cases</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34.053151</td>\n",
       "      <td>24.478082</td>\n",
       "      <td>28.709863</td>\n",
       "      <td>39.757808</td>\n",
       "      <td>25.317808</td>\n",
       "      <td>32.306301</td>\n",
       "      <td>22.971233</td>\n",
       "      <td>73.508219</td>\n",
       "      <td>2.921726</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.911781</td>\n",
       "      <td>50.747945</td>\n",
       "      <td>3.789863</td>\n",
       "      <td>208.097808</td>\n",
       "      <td>17.973699</td>\n",
       "      <td>7.232877</td>\n",
       "      <td>2.558904</td>\n",
       "      <td>1.197260</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34.086179</td>\n",
       "      <td>25.694309</td>\n",
       "      <td>29.464228</td>\n",
       "      <td>41.338211</td>\n",
       "      <td>28.140650</td>\n",
       "      <td>34.423577</td>\n",
       "      <td>23.484553</td>\n",
       "      <td>72.066667</td>\n",
       "      <td>3.783415</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.533333</td>\n",
       "      <td>48.313821</td>\n",
       "      <td>2.884553</td>\n",
       "      <td>222.926016</td>\n",
       "      <td>19.246341</td>\n",
       "      <td>7.504065</td>\n",
       "      <td>1.658537</td>\n",
       "      <td>0.991870</td>\n",
       "      <td>5077.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34.573984</td>\n",
       "      <td>25.417886</td>\n",
       "      <td>29.526829</td>\n",
       "      <td>40.464228</td>\n",
       "      <td>26.560163</td>\n",
       "      <td>33.085366</td>\n",
       "      <td>22.580488</td>\n",
       "      <td>69.424390</td>\n",
       "      <td>3.065854</td>\n",
       "      <td>...</td>\n",
       "      <td>1005.731707</td>\n",
       "      <td>55.621138</td>\n",
       "      <td>4.242276</td>\n",
       "      <td>229.413008</td>\n",
       "      <td>19.802439</td>\n",
       "      <td>7.829268</td>\n",
       "      <td>1.910569</td>\n",
       "      <td>1.170732</td>\n",
       "      <td>7579.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33.020325</td>\n",
       "      <td>25.080488</td>\n",
       "      <td>28.727642</td>\n",
       "      <td>37.878049</td>\n",
       "      <td>26.193496</td>\n",
       "      <td>31.772358</td>\n",
       "      <td>21.752033</td>\n",
       "      <td>69.297561</td>\n",
       "      <td>6.025203</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.359350</td>\n",
       "      <td>50.208130</td>\n",
       "      <td>2.991057</td>\n",
       "      <td>225.421951</td>\n",
       "      <td>19.480488</td>\n",
       "      <td>7.593496</td>\n",
       "      <td>1.300813</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>13706.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30.660976</td>\n",
       "      <td>24.230894</td>\n",
       "      <td>26.774797</td>\n",
       "      <td>36.586992</td>\n",
       "      <td>24.263415</td>\n",
       "      <td>28.943902</td>\n",
       "      <td>24.214634</td>\n",
       "      <td>86.652033</td>\n",
       "      <td>23.336585</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.995935</td>\n",
       "      <td>45.542276</td>\n",
       "      <td>3.886992</td>\n",
       "      <td>176.598374</td>\n",
       "      <td>15.261789</td>\n",
       "      <td>6.186992</td>\n",
       "      <td>0.967480</td>\n",
       "      <td>3.951220</td>\n",
       "      <td>82.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial    tempmax    tempmin       temp  feelslikemax  feelslikemin  \\\n",
       "0       0  34.053151  24.478082  28.709863     39.757808     25.317808   \n",
       "1       1  34.086179  25.694309  29.464228     41.338211     28.140650   \n",
       "2       2  34.573984  25.417886  29.526829     40.464228     26.560163   \n",
       "3       3  33.020325  25.080488  28.727642     37.878049     26.193496   \n",
       "4       4  30.660976  24.230894  26.774797     36.586992     24.263415   \n",
       "\n",
       "   feelslike        dew   humidity     precip  ...  sealevelpressure  \\\n",
       "0  32.306301  22.971233  73.508219   2.921726  ...       1007.911781   \n",
       "1  34.423577  23.484553  72.066667   3.783415  ...       1003.533333   \n",
       "2  33.085366  22.580488  69.424390   3.065854  ...       1005.731707   \n",
       "3  31.772358  21.752033  69.297561   6.025203  ...       1003.359350   \n",
       "4  28.943902  24.214634  86.652033  23.336585  ...       1009.995935   \n",
       "\n",
       "   cloudcover  visibility  solarradiation  solarenergy   uvindex  conditions  \\\n",
       "0   50.747945    3.789863      208.097808    17.973699  7.232877    2.558904   \n",
       "1   48.313821    2.884553      222.926016    19.246341  7.504065    1.658537   \n",
       "2   55.621138    4.242276      229.413008    19.802439  7.829268    1.910569   \n",
       "3   50.208130    2.991057      225.421951    19.480488  7.593496    1.300813   \n",
       "4   45.542276    3.886992      176.598374    15.261789  6.186992    0.967480   \n",
       "\n",
       "   stations    cases  labels  \n",
       "0  1.197260   4925.0  normal  \n",
       "1  0.991870   5077.0  normal  \n",
       "2  1.170732   7579.0  normal  \n",
       "3  0.146341  13706.0  normal  \n",
       "4  3.951220     82.0  normal  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('./Dataset/Dengue.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing initial checks on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>precipprob</th>\n",
       "      <th>precipcover</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>winddir</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>conditions</th>\n",
       "      <th>stations</th>\n",
       "      <th>cases</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>300.500000</td>\n",
       "      <td>31.918079</td>\n",
       "      <td>24.588318</td>\n",
       "      <td>27.813181</td>\n",
       "      <td>38.476069</td>\n",
       "      <td>25.613154</td>\n",
       "      <td>31.485111</td>\n",
       "      <td>23.984349</td>\n",
       "      <td>81.254786</td>\n",
       "      <td>13.120862</td>\n",
       "      <td>69.625588</td>\n",
       "      <td>9.034032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.599554</td>\n",
       "      <td>191.498693</td>\n",
       "      <td>1004.690531</td>\n",
       "      <td>59.701192</td>\n",
       "      <td>3.632620</td>\n",
       "      <td>199.802695</td>\n",
       "      <td>17.251785</td>\n",
       "      <td>6.877674</td>\n",
       "      <td>1.827725</td>\n",
       "      <td>0.859734</td>\n",
       "      <td>8502.342193</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>173.926709</td>\n",
       "      <td>2.737215</td>\n",
       "      <td>2.727919</td>\n",
       "      <td>2.412416</td>\n",
       "      <td>4.776400</td>\n",
       "      <td>4.178797</td>\n",
       "      <td>4.672951</td>\n",
       "      <td>2.668014</td>\n",
       "      <td>9.406354</td>\n",
       "      <td>28.463365</td>\n",
       "      <td>45.539264</td>\n",
       "      <td>14.201016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.980189</td>\n",
       "      <td>81.604668</td>\n",
       "      <td>41.364967</td>\n",
       "      <td>20.832639</td>\n",
       "      <td>1.890352</td>\n",
       "      <td>54.128192</td>\n",
       "      <td>4.676051</td>\n",
       "      <td>1.763928</td>\n",
       "      <td>1.237389</td>\n",
       "      <td>0.973575</td>\n",
       "      <td>6780.749627</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.740000</td>\n",
       "      <td>18.820000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.360000</td>\n",
       "      <td>18.626667</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>40.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>57.900000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>150.250000</td>\n",
       "      <td>30.025000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>35.600000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>75.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>134.425000</td>\n",
       "      <td>1002.025000</td>\n",
       "      <td>47.400000</td>\n",
       "      <td>2.523780</td>\n",
       "      <td>160.350000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3017.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>300.500000</td>\n",
       "      <td>31.700000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>38.400000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>24.529268</td>\n",
       "      <td>82.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.589178</td>\n",
       "      <td>207.300000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>63.700000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>205.750000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7490.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>450.750000</td>\n",
       "      <td>33.600000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>29.448171</td>\n",
       "      <td>41.900000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>34.875000</td>\n",
       "      <td>25.475000</td>\n",
       "      <td>88.175000</td>\n",
       "      <td>12.589000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.705508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.775000</td>\n",
       "      <td>252.375000</td>\n",
       "      <td>1010.185772</td>\n",
       "      <td>73.200000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>238.800610</td>\n",
       "      <td>20.600610</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12702.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>601.000000</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>37.900000</td>\n",
       "      <td>42.900000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>99.300000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>83.330000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>359.200000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>97.900000</td>\n",
       "      <td>24.033333</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24983.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            serial     tempmax     tempmin        temp  feelslikemax  \\\n",
       "count   602.000000  602.000000  602.000000  602.000000    602.000000   \n",
       "unique         NaN         NaN         NaN         NaN           NaN   \n",
       "top            NaN         NaN         NaN         NaN           NaN   \n",
       "freq           NaN         NaN         NaN         NaN           NaN   \n",
       "mean    300.500000   31.918079   24.588318   27.813181     38.476069   \n",
       "std     173.926709    2.737215    2.727919    2.412416      4.776400   \n",
       "min       0.000000   25.000000   12.740000   18.820000     25.000000   \n",
       "25%     150.250000   30.025000   23.200000   26.500000     35.600000   \n",
       "50%     300.500000   31.700000   25.000000   27.900000     38.400000   \n",
       "75%     450.750000   33.600000   26.500000   29.448171     41.900000   \n",
       "max     601.000000   41.200000   29.400000   33.300000     49.600000   \n",
       "\n",
       "        feelslikemin   feelslike         dew    humidity      precip  \\\n",
       "count     602.000000  602.000000  602.000000  602.000000  602.000000   \n",
       "unique           NaN         NaN         NaN         NaN         NaN   \n",
       "top              NaN         NaN         NaN         NaN         NaN   \n",
       "freq             NaN         NaN         NaN         NaN         NaN   \n",
       "mean       25.613154   31.485111   23.984349   81.254786   13.120862   \n",
       "std         4.178797    4.672951    2.668014    9.406354   28.463365   \n",
       "min        12.360000   18.626667    4.480000   40.833333    0.000000   \n",
       "25%        23.200000   28.100000   23.300000   75.800000    0.000000   \n",
       "50%        25.000000   31.500000   24.529268   82.800000    3.000000   \n",
       "75%        26.600000   34.875000   25.475000   88.175000   12.589000   \n",
       "max        37.900000   42.900000   28.100000   99.300000  302.000000   \n",
       "\n",
       "        precipprob  precipcover   snow  snowdepth   windspeed     winddir  \\\n",
       "count   602.000000   602.000000  602.0      602.0  602.000000  602.000000   \n",
       "unique         NaN          NaN    NaN        NaN         NaN         NaN   \n",
       "top            NaN          NaN    NaN        NaN         NaN         NaN   \n",
       "freq           NaN          NaN    NaN        NaN         NaN         NaN   \n",
       "mean     69.625588     9.034032    0.0        0.0   17.599554  191.498693   \n",
       "std      45.539264    14.201016    0.0        0.0    8.980189   81.604668   \n",
       "min       0.000000     0.000000    0.0        0.0    3.600000    0.500000   \n",
       "25%       0.000000     0.000000    0.0        0.0   11.200000  134.425000   \n",
       "50%     100.000000     4.170000    0.0        0.0   15.589178  207.300000   \n",
       "75%     100.000000     9.705508    0.0        0.0   22.775000  252.375000   \n",
       "max     100.000000    83.330000    0.0        0.0   92.500000  359.200000   \n",
       "\n",
       "        sealevelpressure  cloudcover  visibility  solarradiation  solarenergy  \\\n",
       "count         602.000000  602.000000  602.000000      602.000000   602.000000   \n",
       "unique               NaN         NaN         NaN             NaN          NaN   \n",
       "top                  NaN         NaN         NaN             NaN          NaN   \n",
       "freq                 NaN         NaN         NaN             NaN          NaN   \n",
       "mean         1004.690531   59.701192    3.632620      199.802695    17.251785   \n",
       "std            41.364967   20.832639    1.890352       54.128192     4.676051   \n",
       "min             0.000000    0.000000    0.800000       57.900000     5.000000   \n",
       "25%          1002.025000   47.400000    2.523780      160.350000    13.900000   \n",
       "50%          1007.000000   63.700000    3.200000      205.750000    17.750000   \n",
       "75%          1010.185772   73.200000    4.300000      238.800610    20.600610   \n",
       "max          1020.000000   97.900000   24.033333      318.500000    27.700000   \n",
       "\n",
       "           uvindex  conditions    stations         cases  labels  \n",
       "count   602.000000  602.000000  602.000000    602.000000     602  \n",
       "unique         NaN         NaN         NaN           NaN       1  \n",
       "top            NaN         NaN         NaN           NaN  normal  \n",
       "freq           NaN         NaN         NaN           NaN     602  \n",
       "mean      6.877674    1.827725    0.859734   8502.342193     NaN  \n",
       "std       1.763928    1.237389    0.973575   6780.749627     NaN  \n",
       "min       2.000000    0.000000    0.000000     52.000000     NaN  \n",
       "25%       6.000000    1.000000    0.000000   3017.750000     NaN  \n",
       "50%       7.000000    2.000000    1.000000   7490.000000     NaN  \n",
       "75%       8.000000    3.000000    1.000000  12702.500000     NaN  \n",
       "max      10.000000    4.000000    5.000000  24983.000000     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      602.000000\n",
       "mean      8502.342193\n",
       "std       6780.749627\n",
       "min         52.000000\n",
       "25%       3017.750000\n",
       "50%       7490.000000\n",
       "75%      12702.500000\n",
       "max      24983.000000\n",
       "Name: cases, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['cases'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating labels column: might be useful in future to test classification problem\n",
    "raw_df['labels'] = pd.cut(\n",
    "    raw_df['cases'],\n",
    "    bins=[-float('inf'), 2500, 5000, 7500, float('inf')],\n",
    "    labels=[0, 1, 2, 3]\n",
    ").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>precipprob</th>\n",
       "      <th>precipcover</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>winddir</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>conditions</th>\n",
       "      <th>stations</th>\n",
       "      <th>cases</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34.053151</td>\n",
       "      <td>24.478082</td>\n",
       "      <td>28.709863</td>\n",
       "      <td>39.757808</td>\n",
       "      <td>25.317808</td>\n",
       "      <td>32.306301</td>\n",
       "      <td>22.971233</td>\n",
       "      <td>73.508219</td>\n",
       "      <td>2.921726</td>\n",
       "      <td>44.657534</td>\n",
       "      <td>4.360932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.678356</td>\n",
       "      <td>175.595342</td>\n",
       "      <td>1007.911781</td>\n",
       "      <td>50.747945</td>\n",
       "      <td>3.789863</td>\n",
       "      <td>208.097808</td>\n",
       "      <td>17.973699</td>\n",
       "      <td>7.232877</td>\n",
       "      <td>2.558904</td>\n",
       "      <td>1.197260</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34.086179</td>\n",
       "      <td>25.694309</td>\n",
       "      <td>29.464228</td>\n",
       "      <td>41.338211</td>\n",
       "      <td>28.140650</td>\n",
       "      <td>34.423577</td>\n",
       "      <td>23.484553</td>\n",
       "      <td>72.066667</td>\n",
       "      <td>3.783415</td>\n",
       "      <td>39.837398</td>\n",
       "      <td>2.676748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.574797</td>\n",
       "      <td>158.349593</td>\n",
       "      <td>1003.533333</td>\n",
       "      <td>48.313821</td>\n",
       "      <td>2.884553</td>\n",
       "      <td>222.926016</td>\n",
       "      <td>19.246341</td>\n",
       "      <td>7.504065</td>\n",
       "      <td>1.658537</td>\n",
       "      <td>0.991870</td>\n",
       "      <td>5077.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34.573984</td>\n",
       "      <td>25.417886</td>\n",
       "      <td>29.526829</td>\n",
       "      <td>40.464228</td>\n",
       "      <td>26.560163</td>\n",
       "      <td>33.085366</td>\n",
       "      <td>22.580488</td>\n",
       "      <td>69.424390</td>\n",
       "      <td>3.065854</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>2.337805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.978049</td>\n",
       "      <td>202.621138</td>\n",
       "      <td>1005.731707</td>\n",
       "      <td>55.621138</td>\n",
       "      <td>4.242276</td>\n",
       "      <td>229.413008</td>\n",
       "      <td>19.802439</td>\n",
       "      <td>7.829268</td>\n",
       "      <td>1.910569</td>\n",
       "      <td>1.170732</td>\n",
       "      <td>7579.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33.020325</td>\n",
       "      <td>25.080488</td>\n",
       "      <td>28.727642</td>\n",
       "      <td>37.878049</td>\n",
       "      <td>26.193496</td>\n",
       "      <td>31.772358</td>\n",
       "      <td>21.752033</td>\n",
       "      <td>69.297561</td>\n",
       "      <td>6.025203</td>\n",
       "      <td>37.398374</td>\n",
       "      <td>2.676667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.504878</td>\n",
       "      <td>183.544715</td>\n",
       "      <td>1003.359350</td>\n",
       "      <td>50.208130</td>\n",
       "      <td>2.991057</td>\n",
       "      <td>225.421951</td>\n",
       "      <td>19.480488</td>\n",
       "      <td>7.593496</td>\n",
       "      <td>1.300813</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>13706.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30.660976</td>\n",
       "      <td>24.230894</td>\n",
       "      <td>26.774797</td>\n",
       "      <td>36.586992</td>\n",
       "      <td>24.263415</td>\n",
       "      <td>28.943902</td>\n",
       "      <td>24.214634</td>\n",
       "      <td>86.652033</td>\n",
       "      <td>23.336585</td>\n",
       "      <td>96.747967</td>\n",
       "      <td>15.616992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.546341</td>\n",
       "      <td>224.030081</td>\n",
       "      <td>1009.995935</td>\n",
       "      <td>45.542276</td>\n",
       "      <td>3.886992</td>\n",
       "      <td>176.598374</td>\n",
       "      <td>15.261789</td>\n",
       "      <td>6.186992</td>\n",
       "      <td>0.967480</td>\n",
       "      <td>3.951220</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial    tempmax    tempmin       temp  feelslikemax  feelslikemin  \\\n",
       "0       0  34.053151  24.478082  28.709863     39.757808     25.317808   \n",
       "1       1  34.086179  25.694309  29.464228     41.338211     28.140650   \n",
       "2       2  34.573984  25.417886  29.526829     40.464228     26.560163   \n",
       "3       3  33.020325  25.080488  28.727642     37.878049     26.193496   \n",
       "4       4  30.660976  24.230894  26.774797     36.586992     24.263415   \n",
       "\n",
       "   feelslike        dew   humidity     precip  precipprob  precipcover  snow  \\\n",
       "0  32.306301  22.971233  73.508219   2.921726   44.657534     4.360932   0.0   \n",
       "1  34.423577  23.484553  72.066667   3.783415   39.837398     2.676748   0.0   \n",
       "2  33.085366  22.580488  69.424390   3.065854   33.333333     2.337805   0.0   \n",
       "3  31.772358  21.752033  69.297561   6.025203   37.398374     2.676667   0.0   \n",
       "4  28.943902  24.214634  86.652033  23.336585   96.747967    15.616992   0.0   \n",
       "\n",
       "   snowdepth  windspeed     winddir  sealevelpressure  cloudcover  visibility  \\\n",
       "0        0.0  15.678356  175.595342       1007.911781   50.747945    3.789863   \n",
       "1        0.0  14.574797  158.349593       1003.533333   48.313821    2.884553   \n",
       "2        0.0  14.978049  202.621138       1005.731707   55.621138    4.242276   \n",
       "3        0.0  16.504878  183.544715       1003.359350   50.208130    2.991057   \n",
       "4        0.0  19.546341  224.030081       1009.995935   45.542276    3.886992   \n",
       "\n",
       "   solarradiation  solarenergy   uvindex  conditions  stations    cases  \\\n",
       "0      208.097808    17.973699  7.232877    2.558904  1.197260   4925.0   \n",
       "1      222.926016    19.246341  7.504065    1.658537  0.991870   5077.0   \n",
       "2      229.413008    19.802439  7.829268    1.910569  1.170732   7579.0   \n",
       "3      225.421951    19.480488  7.593496    1.300813  0.146341  13706.0   \n",
       "4      176.598374    15.261789  6.186992    0.967480  3.951220     82.0   \n",
       "\n",
       "   labels  \n",
       "0       1  \n",
       "1       2  \n",
       "2       3  \n",
       "3       3  \n",
       "4       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the input data to neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['serial', 'cases', 'labels', 'stations', 'snow', 'snowdepth'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>precipprob</th>\n",
       "      <th>precipcover</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>winddir</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.053151</td>\n",
       "      <td>24.478082</td>\n",
       "      <td>28.709863</td>\n",
       "      <td>39.757808</td>\n",
       "      <td>25.317808</td>\n",
       "      <td>32.306301</td>\n",
       "      <td>22.971233</td>\n",
       "      <td>73.508219</td>\n",
       "      <td>2.921726</td>\n",
       "      <td>44.657534</td>\n",
       "      <td>4.360932</td>\n",
       "      <td>15.678356</td>\n",
       "      <td>175.595342</td>\n",
       "      <td>1007.911781</td>\n",
       "      <td>50.747945</td>\n",
       "      <td>3.789863</td>\n",
       "      <td>208.097808</td>\n",
       "      <td>17.973699</td>\n",
       "      <td>7.232877</td>\n",
       "      <td>2.558904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.086179</td>\n",
       "      <td>25.694309</td>\n",
       "      <td>29.464228</td>\n",
       "      <td>41.338211</td>\n",
       "      <td>28.140650</td>\n",
       "      <td>34.423577</td>\n",
       "      <td>23.484553</td>\n",
       "      <td>72.066667</td>\n",
       "      <td>3.783415</td>\n",
       "      <td>39.837398</td>\n",
       "      <td>2.676748</td>\n",
       "      <td>14.574797</td>\n",
       "      <td>158.349593</td>\n",
       "      <td>1003.533333</td>\n",
       "      <td>48.313821</td>\n",
       "      <td>2.884553</td>\n",
       "      <td>222.926016</td>\n",
       "      <td>19.246341</td>\n",
       "      <td>7.504065</td>\n",
       "      <td>1.658537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.573984</td>\n",
       "      <td>25.417886</td>\n",
       "      <td>29.526829</td>\n",
       "      <td>40.464228</td>\n",
       "      <td>26.560163</td>\n",
       "      <td>33.085366</td>\n",
       "      <td>22.580488</td>\n",
       "      <td>69.424390</td>\n",
       "      <td>3.065854</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>2.337805</td>\n",
       "      <td>14.978049</td>\n",
       "      <td>202.621138</td>\n",
       "      <td>1005.731707</td>\n",
       "      <td>55.621138</td>\n",
       "      <td>4.242276</td>\n",
       "      <td>229.413008</td>\n",
       "      <td>19.802439</td>\n",
       "      <td>7.829268</td>\n",
       "      <td>1.910569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.020325</td>\n",
       "      <td>25.080488</td>\n",
       "      <td>28.727642</td>\n",
       "      <td>37.878049</td>\n",
       "      <td>26.193496</td>\n",
       "      <td>31.772358</td>\n",
       "      <td>21.752033</td>\n",
       "      <td>69.297561</td>\n",
       "      <td>6.025203</td>\n",
       "      <td>37.398374</td>\n",
       "      <td>2.676667</td>\n",
       "      <td>16.504878</td>\n",
       "      <td>183.544715</td>\n",
       "      <td>1003.359350</td>\n",
       "      <td>50.208130</td>\n",
       "      <td>2.991057</td>\n",
       "      <td>225.421951</td>\n",
       "      <td>19.480488</td>\n",
       "      <td>7.593496</td>\n",
       "      <td>1.300813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.660976</td>\n",
       "      <td>24.230894</td>\n",
       "      <td>26.774797</td>\n",
       "      <td>36.586992</td>\n",
       "      <td>24.263415</td>\n",
       "      <td>28.943902</td>\n",
       "      <td>24.214634</td>\n",
       "      <td>86.652033</td>\n",
       "      <td>23.336585</td>\n",
       "      <td>96.747967</td>\n",
       "      <td>15.616992</td>\n",
       "      <td>19.546341</td>\n",
       "      <td>224.030081</td>\n",
       "      <td>1009.995935</td>\n",
       "      <td>45.542276</td>\n",
       "      <td>3.886992</td>\n",
       "      <td>176.598374</td>\n",
       "      <td>15.261789</td>\n",
       "      <td>6.186992</td>\n",
       "      <td>0.967480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tempmax    tempmin       temp  feelslikemax  feelslikemin  feelslike  \\\n",
       "0  34.053151  24.478082  28.709863     39.757808     25.317808  32.306301   \n",
       "1  34.086179  25.694309  29.464228     41.338211     28.140650  34.423577   \n",
       "2  34.573984  25.417886  29.526829     40.464228     26.560163  33.085366   \n",
       "3  33.020325  25.080488  28.727642     37.878049     26.193496  31.772358   \n",
       "4  30.660976  24.230894  26.774797     36.586992     24.263415  28.943902   \n",
       "\n",
       "         dew   humidity     precip  precipprob  precipcover  windspeed  \\\n",
       "0  22.971233  73.508219   2.921726   44.657534     4.360932  15.678356   \n",
       "1  23.484553  72.066667   3.783415   39.837398     2.676748  14.574797   \n",
       "2  22.580488  69.424390   3.065854   33.333333     2.337805  14.978049   \n",
       "3  21.752033  69.297561   6.025203   37.398374     2.676667  16.504878   \n",
       "4  24.214634  86.652033  23.336585   96.747967    15.616992  19.546341   \n",
       "\n",
       "      winddir  sealevelpressure  cloudcover  visibility  solarradiation  \\\n",
       "0  175.595342       1007.911781   50.747945    3.789863      208.097808   \n",
       "1  158.349593       1003.533333   48.313821    2.884553      222.926016   \n",
       "2  202.621138       1005.731707   55.621138    4.242276      229.413008   \n",
       "3  183.544715       1003.359350   50.208130    2.991057      225.421951   \n",
       "4  224.030081       1009.995935   45.542276    3.886992      176.598374   \n",
       "\n",
       "   solarenergy   uvindex  conditions  \n",
       "0    17.973699  7.232877    2.558904  \n",
       "1    19.246341  7.504065    1.658537  \n",
       "2    19.802439  7.829268    1.910569  \n",
       "3    19.480488  7.593496    1.300813  \n",
       "4    15.261789  6.186992    0.967480  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>precipprob</th>\n",
       "      <th>precipcover</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>winddir</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>conditions</th>\n",
       "      <th>stations</th>\n",
       "      <th>cases</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34.053151</td>\n",
       "      <td>24.478082</td>\n",
       "      <td>28.709863</td>\n",
       "      <td>39.757808</td>\n",
       "      <td>25.317808</td>\n",
       "      <td>32.306301</td>\n",
       "      <td>22.971233</td>\n",
       "      <td>73.508219</td>\n",
       "      <td>2.921726</td>\n",
       "      <td>44.657534</td>\n",
       "      <td>4.360932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.678356</td>\n",
       "      <td>175.595342</td>\n",
       "      <td>1007.911781</td>\n",
       "      <td>50.747945</td>\n",
       "      <td>3.789863</td>\n",
       "      <td>208.097808</td>\n",
       "      <td>17.973699</td>\n",
       "      <td>7.232877</td>\n",
       "      <td>2.558904</td>\n",
       "      <td>1.197260</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34.086179</td>\n",
       "      <td>25.694309</td>\n",
       "      <td>29.464228</td>\n",
       "      <td>41.338211</td>\n",
       "      <td>28.140650</td>\n",
       "      <td>34.423577</td>\n",
       "      <td>23.484553</td>\n",
       "      <td>72.066667</td>\n",
       "      <td>3.783415</td>\n",
       "      <td>39.837398</td>\n",
       "      <td>2.676748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.574797</td>\n",
       "      <td>158.349593</td>\n",
       "      <td>1003.533333</td>\n",
       "      <td>48.313821</td>\n",
       "      <td>2.884553</td>\n",
       "      <td>222.926016</td>\n",
       "      <td>19.246341</td>\n",
       "      <td>7.504065</td>\n",
       "      <td>1.658537</td>\n",
       "      <td>0.991870</td>\n",
       "      <td>5077.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34.573984</td>\n",
       "      <td>25.417886</td>\n",
       "      <td>29.526829</td>\n",
       "      <td>40.464228</td>\n",
       "      <td>26.560163</td>\n",
       "      <td>33.085366</td>\n",
       "      <td>22.580488</td>\n",
       "      <td>69.424390</td>\n",
       "      <td>3.065854</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>2.337805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.978049</td>\n",
       "      <td>202.621138</td>\n",
       "      <td>1005.731707</td>\n",
       "      <td>55.621138</td>\n",
       "      <td>4.242276</td>\n",
       "      <td>229.413008</td>\n",
       "      <td>19.802439</td>\n",
       "      <td>7.829268</td>\n",
       "      <td>1.910569</td>\n",
       "      <td>1.170732</td>\n",
       "      <td>7579.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33.020325</td>\n",
       "      <td>25.080488</td>\n",
       "      <td>28.727642</td>\n",
       "      <td>37.878049</td>\n",
       "      <td>26.193496</td>\n",
       "      <td>31.772358</td>\n",
       "      <td>21.752033</td>\n",
       "      <td>69.297561</td>\n",
       "      <td>6.025203</td>\n",
       "      <td>37.398374</td>\n",
       "      <td>2.676667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.504878</td>\n",
       "      <td>183.544715</td>\n",
       "      <td>1003.359350</td>\n",
       "      <td>50.208130</td>\n",
       "      <td>2.991057</td>\n",
       "      <td>225.421951</td>\n",
       "      <td>19.480488</td>\n",
       "      <td>7.593496</td>\n",
       "      <td>1.300813</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>13706.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30.660976</td>\n",
       "      <td>24.230894</td>\n",
       "      <td>26.774797</td>\n",
       "      <td>36.586992</td>\n",
       "      <td>24.263415</td>\n",
       "      <td>28.943902</td>\n",
       "      <td>24.214634</td>\n",
       "      <td>86.652033</td>\n",
       "      <td>23.336585</td>\n",
       "      <td>96.747967</td>\n",
       "      <td>15.616992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.546341</td>\n",
       "      <td>224.030081</td>\n",
       "      <td>1009.995935</td>\n",
       "      <td>45.542276</td>\n",
       "      <td>3.886992</td>\n",
       "      <td>176.598374</td>\n",
       "      <td>15.261789</td>\n",
       "      <td>6.186992</td>\n",
       "      <td>0.967480</td>\n",
       "      <td>3.951220</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial    tempmax    tempmin       temp  feelslikemax  feelslikemin  \\\n",
       "0       0  34.053151  24.478082  28.709863     39.757808     25.317808   \n",
       "1       1  34.086179  25.694309  29.464228     41.338211     28.140650   \n",
       "2       2  34.573984  25.417886  29.526829     40.464228     26.560163   \n",
       "3       3  33.020325  25.080488  28.727642     37.878049     26.193496   \n",
       "4       4  30.660976  24.230894  26.774797     36.586992     24.263415   \n",
       "\n",
       "   feelslike        dew   humidity     precip  precipprob  precipcover  snow  \\\n",
       "0  32.306301  22.971233  73.508219   2.921726   44.657534     4.360932   0.0   \n",
       "1  34.423577  23.484553  72.066667   3.783415   39.837398     2.676748   0.0   \n",
       "2  33.085366  22.580488  69.424390   3.065854   33.333333     2.337805   0.0   \n",
       "3  31.772358  21.752033  69.297561   6.025203   37.398374     2.676667   0.0   \n",
       "4  28.943902  24.214634  86.652033  23.336585   96.747967    15.616992   0.0   \n",
       "\n",
       "   snowdepth  windspeed     winddir  sealevelpressure  cloudcover  visibility  \\\n",
       "0        0.0  15.678356  175.595342       1007.911781   50.747945    3.789863   \n",
       "1        0.0  14.574797  158.349593       1003.533333   48.313821    2.884553   \n",
       "2        0.0  14.978049  202.621138       1005.731707   55.621138    4.242276   \n",
       "3        0.0  16.504878  183.544715       1003.359350   50.208130    2.991057   \n",
       "4        0.0  19.546341  224.030081       1009.995935   45.542276    3.886992   \n",
       "\n",
       "   solarradiation  solarenergy   uvindex  conditions  stations    cases  \\\n",
       "0      208.097808    17.973699  7.232877    2.558904  1.197260   4925.0   \n",
       "1      222.926016    19.246341  7.504065    1.658537  0.991870   5077.0   \n",
       "2      229.413008    19.802439  7.829268    1.910569  1.170732   7579.0   \n",
       "3      225.421951    19.480488  7.593496    1.300813  0.146341  13706.0   \n",
       "4      176.598374    15.261789  6.186992    0.967480  3.951220     82.0   \n",
       "\n",
       "   labels  \n",
       "0       1  \n",
       "1       2  \n",
       "2       3  \n",
       "3       3  \n",
       "4       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df)\n",
    "# Y_classification = np.array(pd.get_dummies(raw_df['labels'], dtype=int))\n",
    "Y_cl = raw_df['labels']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(602, 20)\n",
      "(602,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "print(Y_cl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting dataset into train  dev and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test  = train_test_split(X, Y_cl, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_, X_test, Y_dev, Y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(421, 20)\n",
      "(90, 20)\n",
      "(91, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_dev_.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = np.mean(X_train,  axis=0, keepdims=True)\n",
    "X_dev = np.std(X_train, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3153459 ,  0.52442687, -0.14897567,  0.59901433,  0.11854252,\n",
       "         0.00627622,  0.89043439,  1.42371925,  1.13709605,  0.67620327,\n",
       "         0.21132408, -0.33143443, -0.86594917, -0.12238367,  0.8091319 ,\n",
       "        -0.53908097, -0.55545085, -0.56680802, -0.98836085,  0.18618026]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = (X_train-X_mean)/X_dev\n",
    "X_train[:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65997314, -0.18924305,  0.05610572,  0.0723754 , -0.35780477,\n",
       "        -0.29046312, -0.37378142, -0.59574256, -0.4406535 ,  0.67620327,\n",
       "         0.77402431, -0.8191061 ,  1.66706419, -0.04326152,  0.57630207,\n",
       "        -0.83323967,  0.0950825 ,  0.08680913,  0.67140407,  1.8219068 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev_ = (X_dev_-X_mean)/X_dev\n",
    "X_dev_[:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09027227, -0.26061004, -0.39507334, -0.05401794, -0.40543949,\n",
       "        -0.5660068 , -0.02261036,  0.3765909 , -0.22478435,  0.67620327,\n",
       "        -0.07036379, -0.61960405,  0.42484335, -0.00674361, -0.4595531 ,\n",
       "        -0.83323967,  0.90414919,  0.88801725,  0.67140407,  1.8219068 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = (X_test-X_mean)/X_dev\n",
    "X_test[:1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transposing the matrices so that each matrix column contains a single training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T\n",
    "X_development = X_dev_.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y, num_classes):\n",
    "    # Creates an identity matrix and selects the rows based on y values\n",
    "    return np.eye(num_classes)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "3    215\n",
       "0     99\n",
       "2     60\n",
       "1     47\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = one_hot_encode(Y_train,4 ).T\n",
    "Y_train[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dev = one_hot_encode(Y_dev, 4).T\n",
    "Y_dev[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = one_hot_encode(Y_test, 4).T\n",
    "Y_test[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 421)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 91)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 421)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model with Weighted classes strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the appropriate class weights based on the value counts of the classes in your `Y_train`, you can use the inverse of the frequency of each class. This way, the less frequent classes will have a higher weight, and the more frequent classes will have a lower weight. This will help the model give more importance to the underrepresented classes.\n",
    "\n",
    "Here's how you can compute the class weights manually:\n",
    "\n",
    "### Formula for Class Weights:\n",
    "\n",
    "weight_i = Total Samples / Count of Class i\n",
    " \n",
    "Where:\n",
    "- \\(N\\) is the total number of samples in your dataset.\n",
    "- \\(\\text{count}_i\\) is the number of occurrences of class \\(i\\).\n",
    "\n",
    "### Steps:\n",
    "1. Compute the total number of samples \\(N\\).\n",
    "2. For each class \\(i\\), compute the inverse frequency (the class weight).\n",
    "\n",
    "These weights can then be used to adjust the loss calculation during training, making the model pay more attention to the less frequent classes. You can apply these weights to the loss function during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.array([[3.5],\n",
    "                          [15],\n",
    "                          [12],\n",
    "                          [3.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier_model_1 = NN(input_size=X_train.shape[0], architecture=[5,5,5,4],activations=['Leaky_ReLU', 'Leaky_ReLU', 'Leaky_ReLU', 'Softmax'] ,loss=\"CCE\", class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, num_epochs=1000, learning_rate=0.1, eval_interval=100,):\n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    dev_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = model.model_train(X_train, Y_train, learning_rate=learning_rate)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Optionally evaluate on dev set\n",
    "        if epoch % eval_interval == 0:\n",
    "            dev_loss, pred = model.evaluate(X_development, Y_dev)\n",
    "            dev_losses.append(dev_loss)\n",
    "            print(f\"Epoch {epoch}: Train Loss = {train_loss}, Dev Loss = {dev_loss}\")\n",
    "\n",
    "    return train_losses, dev_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 934.4870512954508, Dev Loss = 199.9438426016913\n",
      "Epoch 100: Train Loss = 909.4247488998503, Dev Loss = 210.86720717325548\n",
      "Epoch 200: Train Loss = 926.1404651938279, Dev Loss = 219.9957973125887\n",
      "Epoch 300: Train Loss = 924.5878283248577, Dev Loss = 223.0137298571383\n",
      "Epoch 400: Train Loss = 917.0642048818668, Dev Loss = 222.06298763201852\n",
      "Epoch 500: Train Loss = 907.6202500646308, Dev Loss = 219.68013756069755\n",
      "Epoch 600: Train Loss = 899.0211235178701, Dev Loss = 217.65372820542805\n",
      "Epoch 700: Train Loss = 891.1128698272679, Dev Loss = 215.9220372914144\n",
      "Epoch 800: Train Loss = 885.0587569563471, Dev Loss = 214.65371017150477\n",
      "Epoch 900: Train Loss = 879.238058267679, Dev Loss = 213.4249561889836\n",
      "Epoch 1000: Train Loss = 875.3808574875912, Dev Loss = 212.7539440860349\n",
      "Epoch 1100: Train Loss = 872.2068054896288, Dev Loss = 212.1761798228427\n",
      "Epoch 1200: Train Loss = 868.9378842264941, Dev Loss = 211.53363735361827\n",
      "Epoch 1300: Train Loss = 866.1297923692917, Dev Loss = 211.06776260563976\n",
      "Epoch 1400: Train Loss = 863.7414022238465, Dev Loss = 210.75320344123853\n",
      "Epoch 1500: Train Loss = 861.662559959155, Dev Loss = 210.52453794600916\n",
      "Epoch 1600: Train Loss = 859.9531405536759, Dev Loss = 210.32521007897114\n",
      "Epoch 1700: Train Loss = 858.4471467266559, Dev Loss = 210.12987841148035\n",
      "Epoch 1800: Train Loss = 857.1558795040078, Dev Loss = 209.95583797299312\n",
      "Epoch 1900: Train Loss = 855.9806678170675, Dev Loss = 209.79531093654396\n",
      "Epoch 2000: Train Loss = 854.8935154402128, Dev Loss = 209.664793567253\n",
      "Epoch 2100: Train Loss = 853.8240742410695, Dev Loss = 209.55121389398474\n",
      "Epoch 2200: Train Loss = 852.8576582363526, Dev Loss = 209.45036825099666\n",
      "Epoch 2300: Train Loss = 851.9699725331749, Dev Loss = 209.3459276212908\n",
      "Epoch 2400: Train Loss = 851.0647242099991, Dev Loss = 209.2507557745038\n",
      "Epoch 2500: Train Loss = 850.1778460045252, Dev Loss = 209.16631686357056\n",
      "Epoch 2600: Train Loss = 849.1780637519021, Dev Loss = 209.10875536009863\n",
      "Epoch 2700: Train Loss = 848.2571669989527, Dev Loss = 209.05107574687224\n",
      "Epoch 2800: Train Loss = 847.4143259803192, Dev Loss = 208.99907526060588\n",
      "Epoch 2900: Train Loss = 846.60981234511, Dev Loss = 208.9535326761842\n",
      "Epoch 3000: Train Loss = 845.810706234845, Dev Loss = 208.91039104163065\n",
      "Epoch 3100: Train Loss = 845.0698486627498, Dev Loss = 208.8663240092402\n",
      "Epoch 3200: Train Loss = 844.3488518032639, Dev Loss = 208.82525255471683\n",
      "Epoch 3300: Train Loss = 843.5983292530968, Dev Loss = 208.7374717318211\n",
      "Epoch 3400: Train Loss = 842.938738534563, Dev Loss = 208.66272436917203\n",
      "Epoch 3500: Train Loss = 842.3153855975004, Dev Loss = 208.59758638074055\n",
      "Epoch 3600: Train Loss = 841.7102437603238, Dev Loss = 208.54017775751245\n",
      "Epoch 3700: Train Loss = 841.1302474923207, Dev Loss = 208.48954260028077\n",
      "Epoch 3800: Train Loss = 840.5589127337626, Dev Loss = 208.4352791732091\n",
      "Epoch 3900: Train Loss = 839.9823613941654, Dev Loss = 208.38094006626616\n",
      "Epoch 4000: Train Loss = 839.4294955188998, Dev Loss = 208.3321477093719\n",
      "Epoch 4100: Train Loss = 838.8978023190634, Dev Loss = 208.28537535583894\n",
      "Epoch 4200: Train Loss = 838.386253604885, Dev Loss = 208.240983074431\n",
      "Epoch 4300: Train Loss = 837.9111230446924, Dev Loss = 208.21444715386352\n",
      "Epoch 4400: Train Loss = 837.3929331059396, Dev Loss = 208.18493861098182\n",
      "Epoch 4500: Train Loss = 836.9105541932516, Dev Loss = 208.13296383679813\n",
      "Epoch 4600: Train Loss = 836.449817052109, Dev Loss = 208.07984720860193\n",
      "Epoch 4700: Train Loss = 835.9959744621689, Dev Loss = 208.02673039766873\n",
      "Epoch 4800: Train Loss = 835.5534077242582, Dev Loss = 207.9776667164685\n",
      "Epoch 4900: Train Loss = 835.1342058603676, Dev Loss = 207.9322144904647\n",
      "Epoch 5000: Train Loss = 834.7207313311249, Dev Loss = 207.8884078607386\n",
      "Epoch 5100: Train Loss = 834.1435349878572, Dev Loss = 207.8589340844639\n",
      "Epoch 5200: Train Loss = 833.4596891129486, Dev Loss = 207.84319827488517\n",
      "Epoch 5300: Train Loss = 832.822235275717, Dev Loss = 207.8294467130311\n",
      "Epoch 5400: Train Loss = 832.243140344653, Dev Loss = 207.81451033869467\n",
      "Epoch 5500: Train Loss = 831.7158740064908, Dev Loss = 207.79974474945516\n",
      "Epoch 5600: Train Loss = 831.2581737237614, Dev Loss = 207.782989963846\n",
      "Epoch 5700: Train Loss = 830.8235440585715, Dev Loss = 207.76526312395436\n",
      "Epoch 5800: Train Loss = 830.4061733333755, Dev Loss = 207.75012184878958\n",
      "Epoch 5900: Train Loss = 830.0326047331, Dev Loss = 207.73869499240635\n",
      "Epoch 6000: Train Loss = 829.6563845985711, Dev Loss = 207.72480522414162\n",
      "Epoch 6100: Train Loss = 829.2879684377154, Dev Loss = 207.7088280191968\n",
      "Epoch 6200: Train Loss = 828.9343913856945, Dev Loss = 207.69205460536872\n",
      "Epoch 6300: Train Loss = 828.5913018069891, Dev Loss = 207.67389852944964\n",
      "Epoch 6400: Train Loss = 828.2590303278075, Dev Loss = 207.65518245668142\n",
      "Epoch 6500: Train Loss = 827.9281573782673, Dev Loss = 207.63352037068617\n",
      "Epoch 6600: Train Loss = 827.6002341224219, Dev Loss = 207.60652963835227\n",
      "Epoch 6700: Train Loss = 827.2870599382311, Dev Loss = 207.5785708103221\n",
      "Epoch 6800: Train Loss = 826.9808699881522, Dev Loss = 207.5514034178453\n",
      "Epoch 6900: Train Loss = 826.6789321653205, Dev Loss = 207.52622714245226\n",
      "Epoch 7000: Train Loss = 826.4030611732154, Dev Loss = 207.50121345208214\n",
      "Epoch 7100: Train Loss = 826.1416160234162, Dev Loss = 207.47552352936566\n",
      "Epoch 7200: Train Loss = 825.8818684806477, Dev Loss = 207.45252191514308\n",
      "Epoch 7300: Train Loss = 825.5924047341175, Dev Loss = 207.43587876135928\n",
      "Epoch 7400: Train Loss = 825.3111719993419, Dev Loss = 207.42126647756533\n",
      "Epoch 7500: Train Loss = 825.0446557527396, Dev Loss = 207.40688217029336\n",
      "Epoch 7600: Train Loss = 824.7820975721826, Dev Loss = 207.39280311366224\n",
      "Epoch 7700: Train Loss = 824.5236546213782, Dev Loss = 207.37957743661758\n",
      "Epoch 7800: Train Loss = 824.2660034166998, Dev Loss = 207.36658517028062\n",
      "Epoch 7900: Train Loss = 824.0064516569491, Dev Loss = 207.354496056905\n",
      "Epoch 8000: Train Loss = 823.7389577098099, Dev Loss = 207.33993666111584\n",
      "Epoch 8100: Train Loss = 823.4796014865026, Dev Loss = 207.32774254085223\n",
      "Epoch 8200: Train Loss = 823.2337191536437, Dev Loss = 207.31950325308262\n",
      "Epoch 8300: Train Loss = 822.984812823801, Dev Loss = 207.3099791653819\n",
      "Epoch 8400: Train Loss = 822.7192702278865, Dev Loss = 207.2950053772979\n",
      "Epoch 8500: Train Loss = 822.4571517165411, Dev Loss = 207.28042445758484\n",
      "Epoch 8600: Train Loss = 822.2001459266277, Dev Loss = 207.2662901183737\n",
      "Epoch 8700: Train Loss = 821.9487328287843, Dev Loss = 207.25293912290675\n",
      "Epoch 8800: Train Loss = 821.7016147883103, Dev Loss = 207.24027947128877\n",
      "Epoch 8900: Train Loss = 821.4623516974474, Dev Loss = 207.22722515615197\n",
      "Epoch 9000: Train Loss = 821.2343572830408, Dev Loss = 207.2132995785421\n",
      "Epoch 9100: Train Loss = 821.0102209795513, Dev Loss = 207.2004254912854\n",
      "Epoch 9200: Train Loss = 820.7902981471493, Dev Loss = 207.18797984274838\n",
      "Epoch 9300: Train Loss = 820.5744098871783, Dev Loss = 207.17592589466665\n",
      "Epoch 9400: Train Loss = 820.3774087120098, Dev Loss = 207.16168635166403\n",
      "Epoch 9500: Train Loss = 820.1914605329289, Dev Loss = 207.1465068536036\n",
      "Epoch 9600: Train Loss = 820.0084088035183, Dev Loss = 207.13181658497297\n",
      "Epoch 9700: Train Loss = 819.8282715439099, Dev Loss = 207.11797313082917\n",
      "Epoch 9800: Train Loss = 819.6499203060276, Dev Loss = 207.10498393991838\n",
      "Epoch 9900: Train Loss = 819.4726068071562, Dev Loss = 207.09284649383235\n",
      "Epoch 10000: Train Loss = 819.2975953493133, Dev Loss = 207.08100912787353\n",
      "Epoch 10100: Train Loss = 819.122516633825, Dev Loss = 207.0694123951763\n",
      "Epoch 10200: Train Loss = 818.951315664183, Dev Loss = 207.0594033855859\n",
      "Epoch 10300: Train Loss = 818.7820490169294, Dev Loss = 207.04985508671828\n",
      "Epoch 10400: Train Loss = 818.6144693834258, Dev Loss = 207.04050104632307\n",
      "Epoch 10500: Train Loss = 818.4481118110932, Dev Loss = 207.03114837827513\n",
      "Epoch 10600: Train Loss = 818.2834688851159, Dev Loss = 207.02193362926687\n",
      "Epoch 10700: Train Loss = 818.1213865459024, Dev Loss = 207.01318191030362\n",
      "Epoch 10800: Train Loss = 817.9606783837256, Dev Loss = 207.00444409679608\n",
      "Epoch 10900: Train Loss = 817.8017428912432, Dev Loss = 206.99602825655967\n",
      "Epoch 11000: Train Loss = 817.6459299604593, Dev Loss = 206.98804733110106\n",
      "Epoch 11100: Train Loss = 817.4911122142017, Dev Loss = 206.98038108696747\n",
      "Epoch 11200: Train Loss = 817.3386029915666, Dev Loss = 206.9727525629697\n",
      "Epoch 11300: Train Loss = 817.1873707269087, Dev Loss = 206.96537043686254\n",
      "Epoch 11400: Train Loss = 817.0351727328604, Dev Loss = 206.95839896128402\n",
      "Epoch 11500: Train Loss = 816.8747023862238, Dev Loss = 206.95001940502038\n",
      "Epoch 11600: Train Loss = 816.7156595077402, Dev Loss = 206.94202159417515\n",
      "Epoch 11700: Train Loss = 816.559187944365, Dev Loss = 206.9341721963283\n",
      "Epoch 11800: Train Loss = 816.4037226753013, Dev Loss = 206.92674576186852\n",
      "Epoch 11900: Train Loss = 816.2513159891367, Dev Loss = 206.91983791112176\n",
      "Epoch 12000: Train Loss = 816.1035853666918, Dev Loss = 206.91436428518728\n",
      "Epoch 12100: Train Loss = 815.9584466107007, Dev Loss = 206.90920892144376\n",
      "Epoch 12200: Train Loss = 815.8146595858167, Dev Loss = 206.90423700463077\n",
      "Epoch 12300: Train Loss = 815.6716513090137, Dev Loss = 206.89920108661005\n",
      "Epoch 12400: Train Loss = 815.5305314900306, Dev Loss = 206.8943660505928\n",
      "Epoch 12500: Train Loss = 815.3912477397636, Dev Loss = 206.88806247288593\n",
      "Epoch 12600: Train Loss = 815.2536581401845, Dev Loss = 206.88228017138556\n",
      "Epoch 12700: Train Loss = 815.1176128214797, Dev Loss = 206.87652961438377\n",
      "Epoch 12800: Train Loss = 814.9825169824126, Dev Loss = 206.87098280715176\n",
      "Epoch 12900: Train Loss = 814.8469793930682, Dev Loss = 206.8653141738673\n",
      "Epoch 13000: Train Loss = 814.7112769109096, Dev Loss = 206.85951587489046\n",
      "Epoch 13100: Train Loss = 814.5838866487987, Dev Loss = 206.85440698617847\n",
      "Epoch 13200: Train Loss = 814.4585508419434, Dev Loss = 206.84840626088723\n",
      "Epoch 13300: Train Loss = 814.3341336564285, Dev Loss = 206.8429714066549\n",
      "Epoch 13400: Train Loss = 814.2108680306686, Dev Loss = 206.8377041862206\n",
      "Epoch 13500: Train Loss = 814.0876535572837, Dev Loss = 206.83249085638587\n",
      "Epoch 13600: Train Loss = 813.9656653702061, Dev Loss = 206.82724350900233\n",
      "Epoch 13700: Train Loss = 813.8430851364311, Dev Loss = 206.8225974862925\n",
      "Epoch 13800: Train Loss = 813.7205112487235, Dev Loss = 206.81784730519956\n",
      "Epoch 13900: Train Loss = 813.5996153548231, Dev Loss = 206.81308396281105\n",
      "Epoch 14000: Train Loss = 813.4790235117188, Dev Loss = 206.8085342188838\n",
      "Epoch 14100: Train Loss = 813.3598083671898, Dev Loss = 206.80402082731084\n",
      "Epoch 14200: Train Loss = 813.2412172199876, Dev Loss = 206.79952658977572\n",
      "Epoch 14300: Train Loss = 813.1182054546377, Dev Loss = 206.79672939333204\n",
      "Epoch 14400: Train Loss = 812.9968872217067, Dev Loss = 206.7939370860181\n",
      "Epoch 14500: Train Loss = 812.8763988108121, Dev Loss = 206.7911519845442\n",
      "Epoch 14600: Train Loss = 812.6728009389831, Dev Loss = 206.79215449159102\n",
      "Epoch 14700: Train Loss = 812.4776749532215, Dev Loss = 206.79319525568008\n",
      "Epoch 14800: Train Loss = 812.3054964264666, Dev Loss = 206.7924945787117\n",
      "Epoch 14900: Train Loss = 812.1173914519334, Dev Loss = 206.79349001211847\n",
      "Epoch 15000: Train Loss = 811.9374429953285, Dev Loss = 206.79437333880983\n",
      "Epoch 15100: Train Loss = 811.7644685872949, Dev Loss = 206.7948782189394\n",
      "Epoch 15200: Train Loss = 811.5974826015921, Dev Loss = 206.79535948940833\n",
      "Epoch 15300: Train Loss = 811.4363310235127, Dev Loss = 206.7955956179037\n",
      "Epoch 15400: Train Loss = 811.280140436789, Dev Loss = 206.79586156475273\n",
      "Epoch 15500: Train Loss = 811.1227797090072, Dev Loss = 206.79478727414647\n",
      "Epoch 15600: Train Loss = 810.9711186043038, Dev Loss = 206.7938396693182\n",
      "Epoch 15700: Train Loss = 810.8260446889688, Dev Loss = 206.7926920403373\n",
      "Epoch 15800: Train Loss = 810.7146727779026, Dev Loss = 206.7905833108934\n",
      "Epoch 15900: Train Loss = 810.6052579676353, Dev Loss = 206.78857169153568\n",
      "Epoch 16000: Train Loss = 810.4966679132832, Dev Loss = 206.7867428802309\n",
      "Epoch 16100: Train Loss = 810.3897481866018, Dev Loss = 206.78493202352325\n",
      "Epoch 16200: Train Loss = 810.2845313997469, Dev Loss = 206.78345321319847\n",
      "Epoch 16300: Train Loss = 810.1793050272646, Dev Loss = 206.7814065863792\n",
      "Epoch 16400: Train Loss = 810.07295333112, Dev Loss = 206.77893145346673\n",
      "Epoch 16500: Train Loss = 809.9651493905405, Dev Loss = 206.77682936620698\n",
      "Epoch 16600: Train Loss = 809.8577729353929, Dev Loss = 206.77490739632177\n",
      "Epoch 16700: Train Loss = 809.7514046272171, Dev Loss = 206.77294458277194\n",
      "Epoch 16800: Train Loss = 809.6441070372937, Dev Loss = 206.77049309438218\n",
      "Epoch 16900: Train Loss = 809.5383326869951, Dev Loss = 206.76819071905317\n",
      "Epoch 17000: Train Loss = 809.4338613538033, Dev Loss = 206.7658671182178\n",
      "Epoch 17100: Train Loss = 809.331336675255, Dev Loss = 206.76350956890317\n",
      "Epoch 17200: Train Loss = 809.228870409402, Dev Loss = 206.7612039721554\n",
      "Epoch 17300: Train Loss = 809.1233822222832, Dev Loss = 206.7593251947495\n",
      "Epoch 17400: Train Loss = 809.019245567297, Dev Loss = 206.75725134984768\n",
      "Epoch 17500: Train Loss = 808.9150902384241, Dev Loss = 206.7547830962117\n",
      "Epoch 17600: Train Loss = 808.8143542104461, Dev Loss = 206.75184540351853\n",
      "Epoch 17700: Train Loss = 808.718891150521, Dev Loss = 206.74863530140263\n",
      "Epoch 17800: Train Loss = 808.6237141396358, Dev Loss = 206.74609588892045\n",
      "Epoch 17900: Train Loss = 808.5258739871517, Dev Loss = 206.7443467273942\n",
      "Epoch 18000: Train Loss = 808.4293537309102, Dev Loss = 206.74256181978564\n",
      "Epoch 18100: Train Loss = 808.3342988726256, Dev Loss = 206.74071970263395\n",
      "Epoch 18200: Train Loss = 808.2405445737134, Dev Loss = 206.7388357648777\n",
      "Epoch 18300: Train Loss = 808.1481135045685, Dev Loss = 206.7369085634515\n",
      "Epoch 18400: Train Loss = 808.0568369707761, Dev Loss = 206.73498186781373\n",
      "Epoch 18500: Train Loss = 807.9667724215424, Dev Loss = 206.73300471181932\n",
      "Epoch 18600: Train Loss = 807.8779681441565, Dev Loss = 206.73100440447962\n",
      "Epoch 18700: Train Loss = 807.7895854614177, Dev Loss = 206.72897410190652\n",
      "Epoch 18800: Train Loss = 807.7002638232285, Dev Loss = 206.72713009662016\n",
      "Epoch 18900: Train Loss = 807.6119205981407, Dev Loss = 206.72526248044846\n",
      "Epoch 19000: Train Loss = 807.5246616622976, Dev Loss = 206.7232928827077\n",
      "Epoch 19100: Train Loss = 807.4381443926316, Dev Loss = 206.72131698425915\n",
      "Epoch 19200: Train Loss = 807.3518437170175, Dev Loss = 206.7191514596467\n",
      "Epoch 19300: Train Loss = 807.2687811044589, Dev Loss = 206.71773893472118\n",
      "Epoch 19400: Train Loss = 807.1898323611745, Dev Loss = 206.71774455195575\n",
      "Epoch 19500: Train Loss = 807.1112414096215, Dev Loss = 206.71756174927745\n",
      "Epoch 19600: Train Loss = 807.0328108400525, Dev Loss = 206.71694606709212\n",
      "Epoch 19700: Train Loss = 806.9546603796874, Dev Loss = 206.71617780242565\n",
      "Epoch 19800: Train Loss = 806.876808582489, Dev Loss = 206.71525734341748\n",
      "Epoch 19900: Train Loss = 806.7995662588276, Dev Loss = 206.7141715907688\n",
      "Epoch 20000: Train Loss = 806.7227749322425, Dev Loss = 206.71309084978904\n",
      "Epoch 20100: Train Loss = 806.6464550396081, Dev Loss = 206.7119751634934\n",
      "Epoch 20200: Train Loss = 806.5705689429936, Dev Loss = 206.71072449887606\n",
      "Epoch 20300: Train Loss = 806.4951227011994, Dev Loss = 206.70946206954684\n",
      "Epoch 20400: Train Loss = 806.4202524882801, Dev Loss = 206.7081040633147\n",
      "Epoch 20500: Train Loss = 806.3457860640784, Dev Loss = 206.7067432967984\n",
      "Epoch 20600: Train Loss = 806.2717096157414, Dev Loss = 206.70364940594158\n",
      "Epoch 20700: Train Loss = 806.1983548383268, Dev Loss = 206.69987365849315\n",
      "Epoch 20800: Train Loss = 806.1253214650079, Dev Loss = 206.69620657564752\n",
      "Epoch 20900: Train Loss = 806.0525696122808, Dev Loss = 206.6925617832986\n",
      "Epoch 21000: Train Loss = 805.9804624484196, Dev Loss = 206.68887752030594\n",
      "Epoch 21100: Train Loss = 805.9088802658453, Dev Loss = 206.6851605448154\n",
      "Epoch 21200: Train Loss = 805.8374681467176, Dev Loss = 206.68143087382754\n",
      "Epoch 21300: Train Loss = 805.7665093765236, Dev Loss = 206.677550124189\n",
      "Epoch 21400: Train Loss = 805.6962095680515, Dev Loss = 206.67374583938448\n",
      "Epoch 21500: Train Loss = 805.6274742768278, Dev Loss = 206.67057147909958\n",
      "Epoch 21600: Train Loss = 805.559430042978, Dev Loss = 206.66738782922369\n",
      "Epoch 21700: Train Loss = 805.4917779880701, Dev Loss = 206.66427912317658\n",
      "Epoch 21800: Train Loss = 805.4245126482678, Dev Loss = 206.66126255389437\n",
      "Epoch 21900: Train Loss = 805.3578561976963, Dev Loss = 206.65828364746002\n",
      "Epoch 22000: Train Loss = 805.2916228504795, Dev Loss = 206.6553484710633\n",
      "Epoch 22100: Train Loss = 805.2257128698116, Dev Loss = 206.65242007453736\n",
      "Epoch 22200: Train Loss = 805.1602945316355, Dev Loss = 206.64955810022113\n",
      "Epoch 22300: Train Loss = 805.0948796830987, Dev Loss = 206.64596349206764\n",
      "Epoch 22400: Train Loss = 805.0291658090584, Dev Loss = 206.64119467748034\n",
      "Epoch 22500: Train Loss = 804.9638088438958, Dev Loss = 206.63646331793325\n",
      "Epoch 22600: Train Loss = 804.8986758785568, Dev Loss = 206.63182730638286\n",
      "Epoch 22700: Train Loss = 804.8342090161085, Dev Loss = 206.62720777082546\n",
      "Epoch 22800: Train Loss = 804.7698629858484, Dev Loss = 206.62264684102823\n",
      "Epoch 22900: Train Loss = 804.706166705067, Dev Loss = 206.61804972288374\n",
      "Epoch 23000: Train Loss = 804.6424071036296, Dev Loss = 206.61360054541106\n",
      "Epoch 23100: Train Loss = 804.5783762285081, Dev Loss = 206.6089657769189\n",
      "Epoch 23200: Train Loss = 804.5146016313935, Dev Loss = 206.6042905375614\n",
      "Epoch 23300: Train Loss = 804.4511092529341, Dev Loss = 206.59971884413028\n",
      "Epoch 23400: Train Loss = 804.3880734225532, Dev Loss = 206.59525603338147\n",
      "Epoch 23500: Train Loss = 804.3253733196188, Dev Loss = 206.59075474551398\n",
      "Epoch 23600: Train Loss = 804.2628671338372, Dev Loss = 206.5863076548508\n",
      "Epoch 23700: Train Loss = 804.2007279482154, Dev Loss = 206.58191973003093\n",
      "Epoch 23800: Train Loss = 804.1386960139434, Dev Loss = 206.57741483436277\n",
      "Epoch 23900: Train Loss = 804.0769326277314, Dev Loss = 206.57287700422074\n",
      "Epoch 24000: Train Loss = 804.0155129093762, Dev Loss = 206.56835937975043\n",
      "Epoch 24100: Train Loss = 803.9546057995087, Dev Loss = 206.5639134163092\n",
      "Epoch 24200: Train Loss = 803.8941131104795, Dev Loss = 206.5595582211695\n",
      "Epoch 24300: Train Loss = 803.8346676268555, Dev Loss = 206.55501755722202\n",
      "Epoch 24400: Train Loss = 803.775383714773, Dev Loss = 206.55068904850515\n",
      "Epoch 24500: Train Loss = 803.7167188505939, Dev Loss = 206.5464227945388\n",
      "Epoch 24600: Train Loss = 803.6583917849358, Dev Loss = 206.5422194125684\n",
      "Epoch 24700: Train Loss = 803.6006067823284, Dev Loss = 206.53796029143913\n",
      "Epoch 24800: Train Loss = 803.5429470824076, Dev Loss = 206.53384886208784\n",
      "Epoch 24900: Train Loss = 803.485639633645, Dev Loss = 206.52969587602743\n",
      "Epoch 25000: Train Loss = 803.4288110705041, Dev Loss = 206.52564877244652\n",
      "Epoch 25100: Train Loss = 803.3721060696679, Dev Loss = 206.5216035439843\n",
      "Epoch 25200: Train Loss = 803.3141361111024, Dev Loss = 206.5177631113448\n",
      "Epoch 25300: Train Loss = 803.2555443699808, Dev Loss = 206.5140103924328\n",
      "Epoch 25400: Train Loss = 803.197580689455, Dev Loss = 206.51028627883093\n",
      "Epoch 25500: Train Loss = 803.1398306065446, Dev Loss = 206.50660419523916\n",
      "Epoch 25600: Train Loss = 803.0826058039765, Dev Loss = 206.502885260946\n",
      "Epoch 25700: Train Loss = 803.0256884840587, Dev Loss = 206.49926782730194\n",
      "Epoch 25800: Train Loss = 802.9693242881116, Dev Loss = 206.49561818278215\n",
      "Epoch 25900: Train Loss = 802.9130486429331, Dev Loss = 206.49201677018786\n",
      "Epoch 26000: Train Loss = 802.8574105199402, Dev Loss = 206.488426218174\n",
      "Epoch 26100: Train Loss = 802.8020813029149, Dev Loss = 206.48487007404657\n",
      "Epoch 26200: Train Loss = 802.7483952593645, Dev Loss = 206.48171435102444\n",
      "Epoch 26300: Train Loss = 802.6950848661505, Dev Loss = 206.47856415252306\n",
      "Epoch 26400: Train Loss = 802.6417138785873, Dev Loss = 206.47522126133114\n",
      "Epoch 26500: Train Loss = 802.5865787827832, Dev Loss = 206.4717875220032\n",
      "Epoch 26600: Train Loss = 802.5318327903545, Dev Loss = 206.46841598875056\n",
      "Epoch 26700: Train Loss = 802.4774554127728, Dev Loss = 206.46500887595653\n",
      "Epoch 26800: Train Loss = 802.4235445472771, Dev Loss = 206.46168606798238\n",
      "Epoch 26900: Train Loss = 802.369961931631, Dev Loss = 206.4584344568782\n",
      "Epoch 27000: Train Loss = 802.3168199080012, Dev Loss = 206.45512038520494\n",
      "Epoch 27100: Train Loss = 802.2638514165956, Dev Loss = 206.4519069996816\n",
      "Epoch 27200: Train Loss = 802.2111432280358, Dev Loss = 206.44875386982497\n",
      "Epoch 27300: Train Loss = 802.1587739489016, Dev Loss = 206.4456031419663\n",
      "Epoch 27400: Train Loss = 802.1066320659058, Dev Loss = 206.44247739802307\n",
      "Epoch 27500: Train Loss = 802.0549050232929, Dev Loss = 206.4394094909886\n",
      "Epoch 27600: Train Loss = 802.0012200838285, Dev Loss = 206.43659444557863\n",
      "Epoch 27700: Train Loss = 801.9473685228858, Dev Loss = 206.4338694359883\n",
      "Epoch 27800: Train Loss = 801.8939772155147, Dev Loss = 206.43109498477028\n",
      "Epoch 27900: Train Loss = 801.8407645724717, Dev Loss = 206.4284026278719\n",
      "Epoch 28000: Train Loss = 801.7879163606494, Dev Loss = 206.4256712422211\n",
      "Epoch 28100: Train Loss = 801.7354059740643, Dev Loss = 206.42303614619334\n",
      "Epoch 28200: Train Loss = 801.6830691548563, Dev Loss = 206.42037895071834\n",
      "Epoch 28300: Train Loss = 801.6311341268461, Dev Loss = 206.4177631362353\n",
      "Epoch 28400: Train Loss = 801.5793846628543, Dev Loss = 206.4151228996811\n",
      "Epoch 28500: Train Loss = 801.5280456305156, Dev Loss = 206.41253168122176\n",
      "Epoch 28600: Train Loss = 801.4769857013237, Dev Loss = 206.40992983751275\n",
      "Epoch 28700: Train Loss = 801.4253310328763, Dev Loss = 206.40750758682975\n",
      "Epoch 28800: Train Loss = 801.3729378593966, Dev Loss = 206.4052502319373\n",
      "Epoch 28900: Train Loss = 801.2899873902718, Dev Loss = 206.40440016730435\n",
      "Epoch 29000: Train Loss = 801.1061067949838, Dev Loss = 206.40785463434372\n",
      "Epoch 29100: Train Loss = 800.9307260846651, Dev Loss = 206.41131936523976\n",
      "Epoch 29200: Train Loss = 800.634093283741, Dev Loss = 206.41706816718482\n",
      "Epoch 29300: Train Loss = 800.0995535077268, Dev Loss = 206.43067328544214\n",
      "Epoch 29400: Train Loss = 799.5571503020503, Dev Loss = 206.44572746983368\n",
      "Epoch 29500: Train Loss = 799.0365097463451, Dev Loss = 206.46068286705005\n",
      "Epoch 29600: Train Loss = 798.501365419824, Dev Loss = 206.47640707902482\n",
      "Epoch 29700: Train Loss = 797.9955301680848, Dev Loss = 206.49214380495764\n",
      "Epoch 29800: Train Loss = 797.5277101775572, Dev Loss = 206.5067556564769\n",
      "Epoch 29900: Train Loss = 797.0942291012547, Dev Loss = 206.52021195383216\n",
      "Epoch 30000: Train Loss = 796.6866549683758, Dev Loss = 206.53332111824437\n",
      "Epoch 30100: Train Loss = 796.3231689429664, Dev Loss = 206.5442136165632\n",
      "Epoch 30200: Train Loss = 795.9889990486499, Dev Loss = 206.553911825284\n",
      "Epoch 30300: Train Loss = 795.6725002069572, Dev Loss = 206.56331811281004\n",
      "Epoch 30400: Train Loss = 795.3735474760218, Dev Loss = 206.57230000277085\n",
      "Epoch 30500: Train Loss = 795.0910977727988, Dev Loss = 206.58074558815912\n",
      "Epoch 30600: Train Loss = 794.8235889953487, Dev Loss = 206.58881489319413\n",
      "Epoch 30700: Train Loss = 794.568273057655, Dev Loss = 206.59664672494986\n",
      "Epoch 30800: Train Loss = 794.3259629680367, Dev Loss = 206.6039821605636\n",
      "Epoch 30900: Train Loss = 794.0960329769429, Dev Loss = 206.61056955353519\n",
      "Epoch 31000: Train Loss = 793.8778930762905, Dev Loss = 206.6167732515202\n",
      "Epoch 31100: Train Loss = 793.6702479813738, Dev Loss = 206.62341607834827\n",
      "Epoch 31200: Train Loss = 793.4727203332288, Dev Loss = 206.6299276402817\n",
      "Epoch 31300: Train Loss = 793.2847266380041, Dev Loss = 206.63610024737554\n",
      "Epoch 31400: Train Loss = 793.1056482873996, Dev Loss = 206.64180141300187\n",
      "Epoch 31500: Train Loss = 792.9347720858889, Dev Loss = 206.64712439822938\n",
      "Epoch 31600: Train Loss = 792.7717786426972, Dev Loss = 206.6520886037578\n",
      "Epoch 31700: Train Loss = 792.6170093290182, Dev Loss = 206.65667726729504\n",
      "Epoch 31800: Train Loss = 792.4752858643014, Dev Loss = 206.66040698933304\n",
      "Epoch 31900: Train Loss = 792.347245972593, Dev Loss = 206.66295298474307\n",
      "Epoch 32000: Train Loss = 792.2227418456575, Dev Loss = 206.6655146121262\n",
      "Epoch 32100: Train Loss = 792.1008570631525, Dev Loss = 206.66803381842732\n",
      "Epoch 32200: Train Loss = 791.9818566626708, Dev Loss = 206.67045265530814\n",
      "Epoch 32300: Train Loss = 791.8069629124766, Dev Loss = 206.67487074874052\n",
      "Epoch 32400: Train Loss = 791.5990846589941, Dev Loss = 206.68091844493134\n",
      "Epoch 32500: Train Loss = 791.3669810144979, Dev Loss = 206.6879715821894\n",
      "Epoch 32600: Train Loss = 791.1464700877117, Dev Loss = 206.69472830319648\n",
      "Epoch 32700: Train Loss = 790.9365316454675, Dev Loss = 206.70122618199738\n",
      "Epoch 32800: Train Loss = 790.7364290867137, Dev Loss = 206.70746588175703\n",
      "Epoch 32900: Train Loss = 790.5454944593996, Dev Loss = 206.7134430894701\n",
      "Epoch 33000: Train Loss = 790.3631431883259, Dev Loss = 206.71912586667162\n",
      "Epoch 33100: Train Loss = 790.1925526165185, Dev Loss = 206.72427302674689\n",
      "Epoch 33200: Train Loss = 790.0298784453024, Dev Loss = 206.7290686045176\n",
      "Epoch 33300: Train Loss = 789.8702789631417, Dev Loss = 206.73379613524244\n",
      "Epoch 33400: Train Loss = 789.7171982004331, Dev Loss = 206.738304971072\n",
      "Epoch 33500: Train Loss = 789.587553533922, Dev Loss = 206.74180053755273\n",
      "Epoch 33600: Train Loss = 789.4629237228348, Dev Loss = 206.74504062188984\n",
      "Epoch 33700: Train Loss = 789.3438101241496, Dev Loss = 206.74805459077388\n",
      "Epoch 33800: Train Loss = 789.237034322154, Dev Loss = 206.75046811926046\n",
      "Epoch 33900: Train Loss = 789.1414250713156, Dev Loss = 206.75219276453205\n",
      "Epoch 34000: Train Loss = 789.0486187288036, Dev Loss = 206.75377207196013\n",
      "Epoch 34100: Train Loss = 788.9549607473027, Dev Loss = 206.7555074349422\n",
      "Epoch 34200: Train Loss = 788.8635871526818, Dev Loss = 206.75714227364423\n",
      "Epoch 34300: Train Loss = 788.7745283390735, Dev Loss = 206.75864438214808\n",
      "Epoch 34400: Train Loss = 788.6864214834865, Dev Loss = 206.7599834113497\n",
      "Epoch 34500: Train Loss = 788.6005813474324, Dev Loss = 206.76118100782946\n",
      "Epoch 34600: Train Loss = 788.500402345288, Dev Loss = 206.76224744350267\n",
      "Epoch 34700: Train Loss = 788.3548335654364, Dev Loss = 206.76318057209988\n",
      "Epoch 34800: Train Loss = 788.2181802711632, Dev Loss = 206.76382484880895\n",
      "Epoch 34900: Train Loss = 788.0860722058586, Dev Loss = 206.76450411093504\n",
      "Epoch 35000: Train Loss = 787.9563806294871, Dev Loss = 206.76528144727789\n",
      "Epoch 35100: Train Loss = 787.8301615353238, Dev Loss = 206.7662087230907\n",
      "Epoch 35200: Train Loss = 787.7074371668857, Dev Loss = 206.7671209488846\n",
      "Epoch 35300: Train Loss = 787.5883765205782, Dev Loss = 206.76819365400775\n",
      "Epoch 35400: Train Loss = 787.4729417903491, Dev Loss = 206.769473301154\n",
      "Epoch 35500: Train Loss = 787.3610803262866, Dev Loss = 206.77081151302548\n",
      "Epoch 35600: Train Loss = 787.252438668251, Dev Loss = 206.77226955096867\n",
      "Epoch 35700: Train Loss = 787.1402970132849, Dev Loss = 206.77453740319396\n",
      "Epoch 35800: Train Loss = 787.0273111463696, Dev Loss = 206.77720350410758\n",
      "Epoch 35900: Train Loss = 786.9157084288152, Dev Loss = 206.77967617935798\n",
      "Epoch 36000: Train Loss = 786.8025744356894, Dev Loss = 206.7826986676911\n",
      "Epoch 36100: Train Loss = 786.6927542593359, Dev Loss = 206.785976146912\n",
      "Epoch 36200: Train Loss = 786.5919044389537, Dev Loss = 206.78974118039784\n",
      "Epoch 36300: Train Loss = 786.493781957651, Dev Loss = 206.79334008414287\n",
      "Epoch 36400: Train Loss = 786.3984012441282, Dev Loss = 206.79684258397194\n",
      "Epoch 36500: Train Loss = 786.3054798945643, Dev Loss = 206.80017744353594\n",
      "Epoch 36600: Train Loss = 786.2120415888425, Dev Loss = 206.8035007979879\n",
      "Epoch 36700: Train Loss = 786.1184495234215, Dev Loss = 206.80683354130804\n",
      "Epoch 36800: Train Loss = 786.0272253242478, Dev Loss = 206.81007934310918\n",
      "Epoch 36900: Train Loss = 785.9382365250262, Dev Loss = 206.8132143562827\n",
      "Epoch 37000: Train Loss = 785.8513294168173, Dev Loss = 206.81631438894343\n",
      "Epoch 37100: Train Loss = 785.7656659190266, Dev Loss = 206.8189733481606\n",
      "Epoch 37200: Train Loss = 785.6815588627443, Dev Loss = 206.8214012130798\n",
      "Epoch 37300: Train Loss = 785.5993172511386, Dev Loss = 206.8238017503322\n",
      "Epoch 37400: Train Loss = 785.5187756651254, Dev Loss = 206.8261187903032\n",
      "Epoch 37500: Train Loss = 785.4393467604954, Dev Loss = 206.82848970676108\n",
      "Epoch 37600: Train Loss = 785.3582885170024, Dev Loss = 206.8311017418106\n",
      "Epoch 37700: Train Loss = 785.2790831016448, Dev Loss = 206.83373907037304\n",
      "Epoch 37800: Train Loss = 785.2014875575753, Dev Loss = 206.83631148110936\n",
      "Epoch 37900: Train Loss = 785.1253147953719, Dev Loss = 206.83880000842578\n",
      "Epoch 38000: Train Loss = 785.0506582753684, Dev Loss = 206.84127539766274\n",
      "Epoch 38100: Train Loss = 784.9773452944847, Dev Loss = 206.84367180649036\n",
      "Epoch 38200: Train Loss = 784.8967592733445, Dev Loss = 206.84725910205628\n",
      "Epoch 38300: Train Loss = 784.8177902872176, Dev Loss = 206.85083119919756\n",
      "Epoch 38400: Train Loss = 784.7403425278972, Dev Loss = 206.8543247644417\n",
      "Epoch 38500: Train Loss = 784.6644504064727, Dev Loss = 206.8577142075227\n",
      "Epoch 38600: Train Loss = 784.5899504182381, Dev Loss = 206.86106934495058\n",
      "Epoch 38700: Train Loss = 784.5168649039006, Dev Loss = 206.8643315406717\n",
      "Epoch 38800: Train Loss = 784.4368436556056, Dev Loss = 206.86795243951687\n",
      "Epoch 38900: Train Loss = 784.3553110269238, Dev Loss = 206.87164924903314\n",
      "Epoch 39000: Train Loss = 784.2757050622387, Dev Loss = 206.87527233528567\n",
      "Epoch 39100: Train Loss = 784.197759439758, Dev Loss = 206.8788138432243\n",
      "Epoch 39200: Train Loss = 784.1148798438556, Dev Loss = 206.8825576446413\n",
      "Epoch 39300: Train Loss = 784.003034173379, Dev Loss = 206.88738647188154\n",
      "Epoch 39400: Train Loss = 783.8941055516868, Dev Loss = 206.89221375420803\n",
      "Epoch 39500: Train Loss = 783.7869432187081, Dev Loss = 206.89695375757535\n",
      "Epoch 39600: Train Loss = 783.6798298148134, Dev Loss = 206.90158400294825\n",
      "Epoch 39700: Train Loss = 783.5750288717081, Dev Loss = 206.90644859179685\n",
      "Epoch 39800: Train Loss = 783.4726787833158, Dev Loss = 206.9113639637873\n",
      "Epoch 39900: Train Loss = 783.37633200722, Dev Loss = 206.9159974041095\n",
      "Epoch 40000: Train Loss = 783.282026583464, Dev Loss = 206.92061735354176\n",
      "Epoch 40100: Train Loss = 783.1887851908666, Dev Loss = 206.9248570059073\n",
      "Epoch 40200: Train Loss = 783.0974003235926, Dev Loss = 206.92906005573715\n",
      "Epoch 40300: Train Loss = 783.0077074492099, Dev Loss = 206.93217647225669\n",
      "Epoch 40400: Train Loss = 782.9197985823571, Dev Loss = 206.93360026967477\n",
      "Epoch 40500: Train Loss = 782.8333563472455, Dev Loss = 206.934969142706\n",
      "Epoch 40600: Train Loss = 782.7484830806216, Dev Loss = 206.93632955451437\n",
      "Epoch 40700: Train Loss = 782.6651066885258, Dev Loss = 206.93770733813278\n",
      "Epoch 40800: Train Loss = 782.5831947780101, Dev Loss = 206.93909237739712\n",
      "Epoch 40900: Train Loss = 782.5025643184952, Dev Loss = 206.94057931303985\n",
      "Epoch 41000: Train Loss = 782.4234108733808, Dev Loss = 206.94221963244078\n",
      "Epoch 41100: Train Loss = 782.3457928563862, Dev Loss = 206.94397346984158\n",
      "Epoch 41200: Train Loss = 782.2696511730093, Dev Loss = 206.94378155266975\n",
      "Epoch 41300: Train Loss = 782.1945955825437, Dev Loss = 206.94148330629898\n",
      "Epoch 41400: Train Loss = 782.1235983540298, Dev Loss = 206.9406360198702\n",
      "Epoch 41500: Train Loss = 782.0577500533128, Dev Loss = 206.94173749629252\n",
      "Epoch 41600: Train Loss = 781.9949493972483, Dev Loss = 206.9427997849918\n",
      "Epoch 41700: Train Loss = 781.9329078393835, Dev Loss = 206.9437267772534\n",
      "Epoch 41800: Train Loss = 781.8711750794944, Dev Loss = 206.94302221106068\n",
      "Epoch 41900: Train Loss = 781.8099981058533, Dev Loss = 206.9422471324605\n",
      "Epoch 42000: Train Loss = 781.7478085504564, Dev Loss = 206.94112172533136\n",
      "Epoch 42100: Train Loss = 781.6852907756795, Dev Loss = 206.93989107892014\n",
      "Epoch 42200: Train Loss = 781.6234588855667, Dev Loss = 206.93873614655527\n",
      "Epoch 42300: Train Loss = 781.5622877097304, Dev Loss = 206.93764524812636\n",
      "Epoch 42400: Train Loss = 781.5018165061244, Dev Loss = 206.9366784951921\n",
      "Epoch 42500: Train Loss = 781.4419539132477, Dev Loss = 206.93573335389743\n",
      "Epoch 42600: Train Loss = 781.3835825845949, Dev Loss = 206.93492849704498\n",
      "Epoch 42700: Train Loss = 781.3268268393381, Dev Loss = 206.93417568764698\n",
      "Epoch 42800: Train Loss = 781.2704137155226, Dev Loss = 206.93340533566322\n",
      "Epoch 42900: Train Loss = 781.2272439479676, Dev Loss = 206.93374453993226\n",
      "Epoch 43000: Train Loss = 781.1899107776414, Dev Loss = 206.93457881204284\n",
      "Epoch 43100: Train Loss = 781.1517957297492, Dev Loss = 206.93537694749583\n",
      "Epoch 43200: Train Loss = 781.1056965847118, Dev Loss = 206.9369532957229\n",
      "Epoch 43300: Train Loss = 781.0598124522212, Dev Loss = 206.93870047773444\n",
      "Epoch 43400: Train Loss = 781.0140430294404, Dev Loss = 206.94037044168527\n",
      "Epoch 43500: Train Loss = 780.968456925498, Dev Loss = 206.94197762021207\n",
      "Epoch 43600: Train Loss = 780.9230018464701, Dev Loss = 206.94352492011154\n",
      "Epoch 43700: Train Loss = 780.8777316491206, Dev Loss = 206.94500902556845\n",
      "Epoch 43800: Train Loss = 780.8326151467141, Dev Loss = 206.94644218331194\n",
      "Epoch 43900: Train Loss = 780.7876432762106, Dev Loss = 206.9478289855882\n",
      "Epoch 44000: Train Loss = 780.7428108207238, Dev Loss = 206.9491434036067\n",
      "Epoch 44100: Train Loss = 780.6982001319533, Dev Loss = 206.95044662705615\n",
      "Epoch 44200: Train Loss = 780.6536951708362, Dev Loss = 206.95169845171807\n",
      "Epoch 44300: Train Loss = 780.6093769828216, Dev Loss = 206.95291491381903\n",
      "Epoch 44400: Train Loss = 780.5652360724504, Dev Loss = 206.95410906436504\n",
      "Epoch 44500: Train Loss = 780.5212648770065, Dev Loss = 206.95528486707735\n",
      "Epoch 44600: Train Loss = 780.4774574299663, Dev Loss = 206.95645262010723\n",
      "Epoch 44700: Train Loss = 780.4337936121331, Dev Loss = 206.9575640950533\n",
      "Epoch 44800: Train Loss = 780.3903546879089, Dev Loss = 206.9586956896407\n",
      "Epoch 44900: Train Loss = 780.3470590312996, Dev Loss = 206.9597816745904\n",
      "Epoch 45000: Train Loss = 780.3036209426969, Dev Loss = 206.96080341733577\n",
      "Epoch 45100: Train Loss = 780.25913398942, Dev Loss = 206.96174376603238\n",
      "Epoch 45200: Train Loss = 780.2170720098206, Dev Loss = 206.96246324021604\n",
      "Epoch 45300: Train Loss = 780.1807026901795, Dev Loss = 206.96271086463472\n",
      "Epoch 45400: Train Loss = 780.1442399939177, Dev Loss = 206.96299352343303\n",
      "Epoch 45500: Train Loss = 780.1076916438419, Dev Loss = 206.9633088074671\n",
      "Epoch 45600: Train Loss = 780.0711068555786, Dev Loss = 206.96366076064598\n",
      "Epoch 45700: Train Loss = 780.0344456212088, Dev Loss = 206.96406257565465\n",
      "Epoch 45800: Train Loss = 779.9977297030858, Dev Loss = 206.9645427608151\n",
      "Epoch 45900: Train Loss = 779.9609441602378, Dev Loss = 206.96504221073025\n",
      "Epoch 46000: Train Loss = 779.9241372692678, Dev Loss = 206.96556099840322\n",
      "Epoch 46100: Train Loss = 779.8872496872276, Dev Loss = 206.96610431624055\n",
      "Epoch 46200: Train Loss = 779.8503440541845, Dev Loss = 206.96667062352319\n",
      "Epoch 46300: Train Loss = 779.8133615584458, Dev Loss = 206.96724801505138\n",
      "Epoch 46400: Train Loss = 779.7753580843893, Dev Loss = 206.96781208497814\n",
      "Epoch 46500: Train Loss = 779.7353478667055, Dev Loss = 206.9683229251097\n",
      "Epoch 46600: Train Loss = 779.6953806533252, Dev Loss = 206.96884659562878\n",
      "Epoch 46700: Train Loss = 779.6642820767046, Dev Loss = 206.9722428246574\n",
      "Epoch 46800: Train Loss = 779.6334023703145, Dev Loss = 206.975591803984\n",
      "Epoch 46900: Train Loss = 779.6021688828405, Dev Loss = 206.9788225129792\n",
      "Epoch 47000: Train Loss = 779.5703195050492, Dev Loss = 206.98176990831848\n",
      "Epoch 47100: Train Loss = 779.5380846347867, Dev Loss = 206.98447040969887\n",
      "Epoch 47200: Train Loss = 779.5055309167344, Dev Loss = 206.98695952667407\n",
      "Epoch 47300: Train Loss = 779.4723682051076, Dev Loss = 206.98924594559517\n",
      "Epoch 47400: Train Loss = 779.4389454438445, Dev Loss = 206.99132114184064\n",
      "Epoch 47500: Train Loss = 779.4052895451375, Dev Loss = 206.99320944614885\n",
      "Epoch 47600: Train Loss = 779.3711537890771, Dev Loss = 206.99497981808614\n",
      "Epoch 47700: Train Loss = 779.3368467905294, Dev Loss = 206.99658550810568\n",
      "Epoch 47800: Train Loss = 779.3023042194718, Dev Loss = 206.99805058869993\n",
      "Epoch 47900: Train Loss = 779.2675586669537, Dev Loss = 206.99937937494036\n",
      "Epoch 48000: Train Loss = 779.2328221693559, Dev Loss = 207.0006669068324\n",
      "Epoch 48100: Train Loss = 779.1987469315529, Dev Loss = 207.00194837474317\n",
      "Epoch 48200: Train Loss = 779.1643392034516, Dev Loss = 207.00302932520873\n",
      "Epoch 48300: Train Loss = 779.1297710389143, Dev Loss = 207.00404420132324\n",
      "Epoch 48400: Train Loss = 779.0952452800191, Dev Loss = 207.00495764040517\n",
      "Epoch 48500: Train Loss = 779.0604243819512, Dev Loss = 207.00586898982223\n",
      "Epoch 48600: Train Loss = 779.025489878652, Dev Loss = 207.00660960187813\n",
      "Epoch 48700: Train Loss = 778.9904776745618, Dev Loss = 207.00729942864405\n",
      "Epoch 48800: Train Loss = 778.9554375468828, Dev Loss = 207.00793812678643\n",
      "Epoch 48900: Train Loss = 778.9203865813336, Dev Loss = 207.00855829716386\n",
      "Epoch 49000: Train Loss = 778.8852519666145, Dev Loss = 207.00911984019427\n",
      "Epoch 49100: Train Loss = 778.8500261001561, Dev Loss = 207.0095501502447\n",
      "Epoch 49200: Train Loss = 778.8145995955955, Dev Loss = 207.01001567275233\n",
      "Epoch 49300: Train Loss = 778.7793642001697, Dev Loss = 207.01047384084282\n",
      "Epoch 49400: Train Loss = 778.7479439687688, Dev Loss = 207.0106235020342\n",
      "Epoch 49500: Train Loss = 778.7200383491357, Dev Loss = 207.01041209131887\n",
      "Epoch 49600: Train Loss = 778.6864759006123, Dev Loss = 207.010686606535\n",
      "Epoch 49700: Train Loss = 778.6527709663017, Dev Loss = 207.01102809373035\n",
      "Epoch 49800: Train Loss = 778.6191000114662, Dev Loss = 207.0113229363513\n",
      "Epoch 49900: Train Loss = 778.5858490288861, Dev Loss = 207.01160309936225\n"
     ]
    }
   ],
   "source": [
    "train_loss, dev_loss = model_train(model=Classifier_model_1, learning_rate=0.5, num_epochs=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d69590b110>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, c='r')\n",
    "plt.plot(range(1,50001, 100), dev_loss, c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, pred = Classifier_model_1.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.857142857142857)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum(np.where(np.argmax(Y_test, axis=0, keepdims=True) == np.argmax(pred, axis=0, keepdims=True)))/Y_test.shape[1]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d697cf8d40>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.argmax(Y_test,axis=0, keepdims=True).flatten()\n",
    "plt.scatter(range(len(data)), data, c=\"b\")  # Scatter plot\n",
    "plt.scatter(range(len(pred)), pred.flatten(), c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and grads of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW4\n",
      "[[ 2.01504190e-06 -3.48473762e-04  1.02022836e-02  9.23263179e-03\n",
      "   9.87900222e-03]\n",
      " [-2.24110492e-04 -2.51867299e-04 -1.05753910e-02 -1.02577598e-03\n",
      "   5.99526606e-03]\n",
      " [-4.40871014e-05 -1.39602903e-04 -3.96262841e-03 -3.22194904e-03\n",
      "  -9.12903875e-03]\n",
      " [ 2.66182552e-04  7.39943963e-04  4.33573582e-03 -4.98490677e-03\n",
      "  -6.74522953e-03]]\n",
      "db4\n",
      "[[-0.02873701]\n",
      " [ 0.01278061]\n",
      " [ 0.01676087]\n",
      " [-0.00080446]]\n",
      "dW3\n",
      "[[ 2.82535187e-04 -1.82267217e-04 -2.10375497e-04  5.67155050e-04\n",
      "   2.16404360e-04]\n",
      " [-8.70812269e-05  9.67615125e-05  6.50029106e-05 -4.29454541e-05\n",
      "   1.36755831e-04]\n",
      " [-8.29532024e-03 -3.99176666e-03  8.33418065e-04  3.04582140e-03\n",
      "   7.01222395e-04]\n",
      " [-6.04643461e-03 -2.11715246e-03  2.81110577e-04 -8.46155842e-03\n",
      "   3.89147462e-03]\n",
      " [-1.48634456e-04  7.38510088e-03  4.88027190e-03 -6.89610935e-03\n",
      "  -1.10334242e-03]]\n",
      "db3\n",
      "[[-0.00035471]\n",
      " [ 0.00016139]\n",
      " [-0.00247964]\n",
      " [-0.00333976]\n",
      " [ 0.00456718]]\n",
      "dW2\n",
      "[[-4.75770134e-04 -6.83019805e-03 -7.30213795e-03 -8.25851621e-05\n",
      "  -7.27248533e-04]\n",
      " [-2.36789647e-03 -4.67237226e-03  4.28268246e-03  2.56023697e-03\n",
      "   2.63409473e-03]\n",
      " [-2.44143214e-04 -1.40590500e-03  2.48828645e-03  2.58939399e-03\n",
      "  -1.89793984e-03]\n",
      " [-3.44487391e-03 -1.79686863e-03  1.73589756e-02 -1.14119950e-03\n",
      "   4.70627952e-03]\n",
      " [ 3.97162568e-03 -2.74934149e-03 -4.34354149e-03 -1.70711220e-04\n",
      "  -1.63851769e-03]]\n",
      "db2\n",
      "[[-0.01141633]\n",
      " [-0.0053501 ]\n",
      " [-0.00097117]\n",
      " [ 0.00496208]\n",
      " [ 0.00289452]]\n",
      "dW1\n",
      "[[-1.96402659e-03  6.47383734e-05 -4.34639914e-03  7.25670681e-04\n",
      "   1.64973946e-03 -3.58549900e-03  2.51864998e-03  7.91555524e-03\n",
      "  -1.82294054e-03 -3.23003628e-04  3.62085978e-04 -5.43174060e-03\n",
      "   2.39698736e-03  4.12660155e-05  1.24558517e-02  3.51829915e-03\n",
      "   2.13605134e-03  1.97918024e-03  3.94279274e-03  8.73454238e-03]\n",
      " [ 1.98288889e-03 -1.71187717e-03 -2.81494507e-03 -2.95407340e-03\n",
      "  -2.91828283e-05 -5.72669028e-03 -4.81418127e-03 -3.91592440e-03\n",
      "  -3.54422895e-03 -3.37470061e-03  8.87768302e-03 -9.06542572e-03\n",
      "   4.35742294e-03  4.13850507e-04  1.29567524e-03  3.52631841e-03\n",
      "  -4.93358574e-03 -4.81374409e-03 -6.01932275e-03  9.85897512e-03]\n",
      " [ 3.24661760e-03 -2.31224860e-03  4.55664594e-04 -1.43917721e-03\n",
      "  -4.69274885e-04 -3.02368537e-03 -5.25483790e-04  1.03106560e-03\n",
      "   9.72411933e-03 -7.84384979e-04 -1.97020005e-03  2.43289747e-03\n",
      "   4.61872751e-03 -7.50461069e-03  9.16836241e-04  8.78218074e-03\n",
      "   2.93918137e-03  2.67038788e-03  4.49607401e-03 -8.49296318e-03]\n",
      " [ 4.49588239e-03  1.31934515e-03  2.26573777e-03  1.72439047e-03\n",
      "   4.96866919e-03  7.21939537e-04  9.05490836e-03  9.82346585e-03\n",
      "   2.66716516e-04 -6.86518258e-03 -2.26213717e-03 -7.95436143e-03\n",
      "   4.24171620e-03 -6.70835832e-04 -4.09985099e-03 -1.09071870e-02\n",
      "  -1.20128854e-03 -1.15829550e-03 -1.12815511e-03  8.32903362e-03]\n",
      " [-4.40296664e-03 -4.95326898e-04  1.66956233e-03 -6.39205657e-04\n",
      "   2.67188445e-04  2.52209812e-03 -3.07973445e-03 -4.19083672e-03\n",
      "  -3.23049922e-04  2.69906469e-04  1.18765956e-03 -1.53483564e-03\n",
      "  -2.58894397e-03 -1.58053322e-03  5.74501952e-03 -8.54051569e-03\n",
      "   2.18664629e-03  2.11567020e-03  1.30211158e-03  2.34854354e-03]]\n",
      "db1\n",
      "[[-0.00183086]\n",
      " [-0.00054295]\n",
      " [-0.00083181]\n",
      " [ 0.00025099]\n",
      " [ 0.00228925]]\n"
     ]
    }
   ],
   "source": [
    "for i in Classifier_model_1.grads:\n",
    "    print(i)\n",
    "    print(Classifier_model_1.grads[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1\n",
      "[[ 0.14448878  0.1427592  -0.22332228  1.02302673 -0.00589812  0.43139844\n",
      "   0.07319129 -0.21108059  0.03956437 -0.41510724  0.09040594  0.173129\n",
      "  -0.11131797  0.05695355  0.30423073  0.32225965  0.25958659 -0.04744521\n",
      "  -0.27257901 -0.43081433]\n",
      " [-0.51044321  0.38090731  0.19958137  0.30665433  0.19651055 -0.20386264\n",
      "   0.29507758  0.29732358  0.22715133 -0.10740794  0.0862672   0.59409723\n",
      "   0.06147589  0.2747375   0.02716567  0.36893706  0.0448015  -0.42922307\n",
      "  -0.03510693 -0.14604511]\n",
      " [-0.32092906 -0.21061961  0.11469365 -0.35676392  0.03008718  0.31446925\n",
      "   0.11844025 -0.15019763  0.09758666 -0.25685829 -0.74414564 -0.29064871\n",
      "   0.74674313 -0.09372945 -0.71901868 -0.56642784  0.34816881 -0.04707945\n",
      "   0.13722243  0.33026743]\n",
      " [ 0.24405848  0.71821501  0.00698488  0.13221419 -0.02443976 -0.34765159\n",
      "  -0.00885515 -0.03255912 -0.32376684 -0.3417988  -0.57452734  0.65904555\n",
      "   0.86952684  0.22189875 -0.23956448  0.504087    0.2620643  -0.2137421\n",
      "   0.20353812 -0.39711954]\n",
      " [-0.32979279 -0.21232865 -0.06749891 -0.41343596 -0.32650594 -0.46911578\n",
      "  -0.21572977  0.27488399 -0.03042475 -0.83767464  0.25265665 -0.56929584\n",
      "   0.20700269  0.1627081   0.10406814  0.39872782  0.43176251 -0.043087\n",
      "   0.05876892 -0.08881196]]\n",
      "b1\n",
      "[[-0.05478663]\n",
      " [ 0.07615971]\n",
      " [ 0.1171627 ]\n",
      " [ 0.0925117 ]\n",
      " [ 0.00483743]]\n",
      "W2\n",
      "[[ 0.87616422  0.61536468  0.61544949  0.96280704 -1.49367422]\n",
      " [-0.36618859  0.92371301  0.35302445 -1.02174807  0.41453724]\n",
      " [ 0.22058497 -0.3310053  -0.70072629 -0.23536941  0.28093285]\n",
      " [ 0.59215496 -0.39866818  0.3336549   1.28427863 -0.47074111]\n",
      " [-0.1069234  -0.00465482  0.7360574  -0.27225186  0.84816554]]\n",
      "b2\n",
      "[[ 0.26633218]\n",
      " [ 0.03688978]\n",
      " [-0.18640447]\n",
      " [ 0.01193619]\n",
      " [ 0.00765649]]\n",
      "W3\n",
      "[[-0.0091582  -0.13360683 -0.38934339 -0.04455239 -0.41520672]\n",
      " [-1.04590731 -0.78085194 -0.33577523 -0.8441504  -0.39156391]\n",
      " [ 0.89368523  0.48350488 -1.05105077 -0.18394774 -0.28123017]\n",
      " [ 0.62337692  0.52670784  1.20812794  0.37648649 -1.08622198]\n",
      " [ 0.36099448 -0.07608951 -0.37241012 -0.66436114  0.3284917 ]]\n",
      "b3\n",
      "[[ 0.00732283]\n",
      " [-0.00760231]\n",
      " [ 0.00261785]\n",
      " [ 0.30740628]\n",
      " [-0.41160196]]\n",
      "W4\n",
      "[[ 1.16247166  0.09467085 -0.22355729 -0.82384675 -1.04744005]\n",
      " [-0.50809095  0.73282432  0.49262883  0.11976416  0.96614603]\n",
      " [ 0.24264674  0.58423576  0.92025983  0.12479286 -0.4425284 ]\n",
      " [-0.44915989  0.37070191  0.03547116  0.97350648 -0.06251059]]\n",
      "b4\n",
      "[[ 1.10477956]\n",
      " [-0.60304571]\n",
      " [-0.71291771]\n",
      " [ 0.21118386]]\n"
     ]
    }
   ],
   "source": [
    "for i in Classifier_model_1.parameters:\n",
    "    print(i)\n",
    "    print(Classifier_model_1.parameters[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training another model without weighted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier_model_2 = NN(input_size=X_train.shape[0], architecture=[5,5,5,4],activations=['Leaky_ReLU', 'Leaky_ReLU', 'Leaky_ReLU', 'Softmax'] ,loss=\"CCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 218.44463717057937, Dev Loss = 36.34899266226526\n",
      "Epoch 100: Train Loss = 124.54889759065492, Dev Loss = 29.924633037005393\n",
      "Epoch 200: Train Loss = 121.54381612630168, Dev Loss = 29.98032867039839\n",
      "Epoch 300: Train Loss = 119.83061762216771, Dev Loss = 29.909339273380592\n",
      "Epoch 400: Train Loss = 118.45742503420541, Dev Loss = 29.905060048598298\n",
      "Epoch 500: Train Loss = 117.13483334043053, Dev Loss = 29.769264826469016\n",
      "Epoch 600: Train Loss = 115.4567525863975, Dev Loss = 29.54925808722247\n",
      "Epoch 700: Train Loss = 113.48217613982224, Dev Loss = 29.321707630524067\n",
      "Epoch 800: Train Loss = 111.20001922999114, Dev Loss = 29.016312313416634\n",
      "Epoch 900: Train Loss = 108.7901535220004, Dev Loss = 28.491454720361475\n",
      "Epoch 1000: Train Loss = 106.67465402995751, Dev Loss = 28.07682745051604\n",
      "Epoch 1100: Train Loss = 105.06395775879352, Dev Loss = 27.66855522042437\n",
      "Epoch 1200: Train Loss = 103.81187833082714, Dev Loss = 27.357749596246563\n",
      "Epoch 1300: Train Loss = 102.58167838067968, Dev Loss = 27.154034699950063\n",
      "Epoch 1400: Train Loss = 101.54897149682152, Dev Loss = 26.90447593823995\n",
      "Epoch 1500: Train Loss = 100.68803029201446, Dev Loss = 26.708617251994195\n",
      "Epoch 1600: Train Loss = 99.93564296646576, Dev Loss = 26.5485662473775\n",
      "Epoch 1700: Train Loss = 99.27081160894556, Dev Loss = 26.412184272901953\n",
      "Epoch 1800: Train Loss = 98.66923868769231, Dev Loss = 26.285342487366385\n",
      "Epoch 1900: Train Loss = 98.12205791810781, Dev Loss = 26.164387622311253\n",
      "Epoch 2000: Train Loss = 97.63398355336773, Dev Loss = 26.05408241055136\n",
      "Epoch 2100: Train Loss = 97.18610088568309, Dev Loss = 25.952657892202428\n",
      "Epoch 2200: Train Loss = 96.77604875999305, Dev Loss = 25.85472801367385\n",
      "Epoch 2300: Train Loss = 96.40861822450684, Dev Loss = 25.762337776441832\n",
      "Epoch 2400: Train Loss = 96.080632557108, Dev Loss = 25.68187904694705\n",
      "Epoch 2500: Train Loss = 95.77540044782175, Dev Loss = 25.610542355553765\n",
      "Epoch 2600: Train Loss = 95.48751793170435, Dev Loss = 25.53944356560429\n",
      "Epoch 2700: Train Loss = 95.21985560710993, Dev Loss = 25.47255673315072\n",
      "Epoch 2800: Train Loss = 94.97065562063567, Dev Loss = 25.411293886318585\n",
      "Epoch 2900: Train Loss = 94.74363894325754, Dev Loss = 25.355607661689394\n",
      "Epoch 3000: Train Loss = 94.53526611985203, Dev Loss = 25.30962978728739\n",
      "Epoch 3100: Train Loss = 94.34319981344312, Dev Loss = 25.268292467012305\n",
      "Epoch 3200: Train Loss = 94.15610638554158, Dev Loss = 25.223287438492243\n",
      "Epoch 3300: Train Loss = 93.9780112330441, Dev Loss = 25.178659985013876\n",
      "Epoch 3400: Train Loss = 93.79885556371002, Dev Loss = 25.133332546285992\n",
      "Epoch 3500: Train Loss = 93.60709878571194, Dev Loss = 25.078033569404912\n",
      "Epoch 3600: Train Loss = 93.42657576450122, Dev Loss = 25.027184939914488\n",
      "Epoch 3700: Train Loss = 93.26258597743175, Dev Loss = 24.98546713339549\n",
      "Epoch 3800: Train Loss = 93.0860116478444, Dev Loss = 24.942335286847335\n",
      "Epoch 3900: Train Loss = 92.91199667361569, Dev Loss = 24.90152529709792\n",
      "Epoch 4000: Train Loss = 92.7354757106286, Dev Loss = 24.839685310354405\n",
      "Epoch 4100: Train Loss = 92.55796263087737, Dev Loss = 24.76597072323553\n",
      "Epoch 4200: Train Loss = 92.38672847305237, Dev Loss = 24.703525790837467\n",
      "Epoch 4300: Train Loss = 92.21604540043758, Dev Loss = 24.648190091637975\n",
      "Epoch 4400: Train Loss = 92.04009403825893, Dev Loss = 24.59544086183013\n",
      "Epoch 4500: Train Loss = 91.86791768051879, Dev Loss = 24.54908241110538\n",
      "Epoch 4600: Train Loss = 91.70430659020774, Dev Loss = 24.50271059350734\n",
      "Epoch 4700: Train Loss = 91.55539218356398, Dev Loss = 24.454777018395646\n",
      "Epoch 4800: Train Loss = 91.38780305212893, Dev Loss = 24.40159368215937\n",
      "Epoch 4900: Train Loss = 91.22984974048312, Dev Loss = 24.353425173056287\n",
      "Epoch 5000: Train Loss = 91.0989589630392, Dev Loss = 24.317283794230264\n",
      "Epoch 5100: Train Loss = 90.96234320944077, Dev Loss = 24.280130204539113\n",
      "Epoch 5200: Train Loss = 90.8392800170691, Dev Loss = 24.25845432933644\n",
      "Epoch 5300: Train Loss = 90.7222561361315, Dev Loss = 24.240586206431775\n",
      "Epoch 5400: Train Loss = 90.60908881658781, Dev Loss = 24.222664848981722\n",
      "Epoch 5500: Train Loss = 90.50087323377673, Dev Loss = 24.206217426524102\n",
      "Epoch 5600: Train Loss = 90.39676635677816, Dev Loss = 24.195705793321416\n",
      "Epoch 5700: Train Loss = 90.29508932851621, Dev Loss = 24.19176822045385\n",
      "Epoch 5800: Train Loss = 90.19249392403037, Dev Loss = 24.183834349562687\n",
      "Epoch 5900: Train Loss = 90.09622261870649, Dev Loss = 24.175436892040988\n",
      "Epoch 6000: Train Loss = 90.00604105898645, Dev Loss = 24.166853601158447\n",
      "Epoch 6100: Train Loss = 89.88080581370093, Dev Loss = 24.156647293507525\n",
      "Epoch 6200: Train Loss = 89.75878288142032, Dev Loss = 24.148907242367827\n",
      "Epoch 6300: Train Loss = 89.64688559918838, Dev Loss = 24.140697220901817\n",
      "Epoch 6400: Train Loss = 89.55025525989053, Dev Loss = 24.134759402115016\n",
      "Epoch 6500: Train Loss = 89.45818991652766, Dev Loss = 24.12820948573628\n",
      "Epoch 6600: Train Loss = 89.37020314514561, Dev Loss = 24.11845033848848\n",
      "Epoch 6700: Train Loss = 89.29181330172406, Dev Loss = 24.115048349358716\n",
      "Epoch 6800: Train Loss = 89.21801665909366, Dev Loss = 24.11429279990151\n",
      "Epoch 6900: Train Loss = 89.14576029278768, Dev Loss = 24.112709250968017\n",
      "Epoch 7000: Train Loss = 89.0735843935492, Dev Loss = 24.110790043502547\n",
      "Epoch 7100: Train Loss = 89.00301193387683, Dev Loss = 24.108859136644497\n",
      "Epoch 7200: Train Loss = 88.93410022519892, Dev Loss = 24.106974071988766\n",
      "Epoch 7300: Train Loss = 88.8688731212367, Dev Loss = 24.105505578680287\n",
      "Epoch 7400: Train Loss = 88.8071587344428, Dev Loss = 24.10516514042392\n",
      "Epoch 7500: Train Loss = 88.7479565043333, Dev Loss = 24.104738852184866\n",
      "Epoch 7600: Train Loss = 88.69042360185824, Dev Loss = 24.103338660789632\n",
      "Epoch 7700: Train Loss = 88.63505700629278, Dev Loss = 24.10031926527182\n",
      "Epoch 7800: Train Loss = 88.58188664729859, Dev Loss = 24.098805590212258\n",
      "Epoch 7900: Train Loss = 88.53065292601457, Dev Loss = 24.096341029174987\n",
      "Epoch 8000: Train Loss = 88.48110778627748, Dev Loss = 24.09477466694867\n",
      "Epoch 8100: Train Loss = 88.4304352914502, Dev Loss = 24.09422659037413\n",
      "Epoch 8200: Train Loss = 88.38186895117882, Dev Loss = 24.09369311348053\n",
      "Epoch 8300: Train Loss = 88.33434047895943, Dev Loss = 24.09260883855252\n",
      "Epoch 8400: Train Loss = 88.28744938584606, Dev Loss = 24.09094354607948\n",
      "Epoch 8500: Train Loss = 88.24215146703789, Dev Loss = 24.090317885403266\n",
      "Epoch 8600: Train Loss = 88.1989756103572, Dev Loss = 24.087938393822473\n",
      "Epoch 8700: Train Loss = 88.15625738807343, Dev Loss = 24.086145759009018\n",
      "Epoch 8800: Train Loss = 88.11301149724987, Dev Loss = 24.08489494833693\n",
      "Epoch 8900: Train Loss = 88.07075375973295, Dev Loss = 24.083159482962074\n",
      "Epoch 9000: Train Loss = 88.02785524577529, Dev Loss = 24.080137252410402\n",
      "Epoch 9100: Train Loss = 87.9845139738869, Dev Loss = 24.07526087910518\n",
      "Epoch 9200: Train Loss = 87.9419698844747, Dev Loss = 24.069752740123114\n",
      "Epoch 9300: Train Loss = 87.90065341384457, Dev Loss = 24.062956360966908\n",
      "Epoch 9400: Train Loss = 87.85986140401215, Dev Loss = 24.056611247994304\n",
      "Epoch 9500: Train Loss = 87.81858380318491, Dev Loss = 24.050637256233486\n",
      "Epoch 9600: Train Loss = 87.77768889621237, Dev Loss = 24.044888015214784\n",
      "Epoch 9700: Train Loss = 87.73717650220928, Dev Loss = 24.039462094240267\n",
      "Epoch 9800: Train Loss = 87.69766925955318, Dev Loss = 24.03463791306415\n",
      "Epoch 9900: Train Loss = 87.65908734628965, Dev Loss = 24.030263118470327\n",
      "Epoch 10000: Train Loss = 87.6215383461689, Dev Loss = 24.026101620382267\n",
      "Epoch 10100: Train Loss = 87.58514031503736, Dev Loss = 24.022509643149323\n",
      "Epoch 10200: Train Loss = 87.55191499187018, Dev Loss = 24.019992488627224\n",
      "Epoch 10300: Train Loss = 87.52092822911108, Dev Loss = 24.016775831824\n",
      "Epoch 10400: Train Loss = 87.49033718575714, Dev Loss = 24.01340570995989\n",
      "Epoch 10500: Train Loss = 87.46087529639517, Dev Loss = 24.012129593601074\n",
      "Epoch 10600: Train Loss = 87.4323317219289, Dev Loss = 24.01103425379023\n",
      "Epoch 10700: Train Loss = 87.40444896943328, Dev Loss = 24.01017495823219\n",
      "Epoch 10800: Train Loss = 87.37698323133148, Dev Loss = 24.009744314996077\n",
      "Epoch 10900: Train Loss = 87.34993045128147, Dev Loss = 24.008666031182724\n",
      "Epoch 11000: Train Loss = 87.32391089117306, Dev Loss = 24.008957558406383\n",
      "Epoch 11100: Train Loss = 87.29811341170819, Dev Loss = 24.008639231360988\n",
      "Epoch 11200: Train Loss = 87.2710540575243, Dev Loss = 24.006088958012676\n",
      "Epoch 11300: Train Loss = 87.24441882651075, Dev Loss = 24.0040278397762\n",
      "Epoch 11400: Train Loss = 87.21819308056702, Dev Loss = 24.002485103009608\n",
      "Epoch 11500: Train Loss = 87.18993132262426, Dev Loss = 24.001232128345265\n",
      "Epoch 11600: Train Loss = 87.16152693396042, Dev Loss = 24.000546568689266\n",
      "Epoch 11700: Train Loss = 87.13381959832031, Dev Loss = 23.998036093654488\n",
      "Epoch 11800: Train Loss = 87.10446163502517, Dev Loss = 23.996673753505913\n",
      "Epoch 11900: Train Loss = 87.0744439096647, Dev Loss = 23.995843155617795\n",
      "Epoch 12000: Train Loss = 87.04459607837188, Dev Loss = 23.995424104151898\n",
      "Epoch 12100: Train Loss = 87.01538490271052, Dev Loss = 23.99458197729169\n",
      "Epoch 12200: Train Loss = 86.98606187917345, Dev Loss = 23.9943940055079\n",
      "Epoch 12300: Train Loss = 86.95838973995495, Dev Loss = 23.99395849174011\n",
      "Epoch 12400: Train Loss = 86.9313700854052, Dev Loss = 23.993050059381037\n",
      "Epoch 12500: Train Loss = 86.90423030470373, Dev Loss = 23.991562396021973\n",
      "Epoch 12600: Train Loss = 86.87568261082626, Dev Loss = 23.989645546572447\n",
      "Epoch 12700: Train Loss = 86.8478900319177, Dev Loss = 23.98763074110809\n",
      "Epoch 12800: Train Loss = 86.82065655441576, Dev Loss = 23.98479344156693\n",
      "Epoch 12900: Train Loss = 86.79447973202501, Dev Loss = 23.982015936916163\n",
      "Epoch 13000: Train Loss = 86.76808408017224, Dev Loss = 23.9804604013473\n",
      "Epoch 13100: Train Loss = 86.74072718746041, Dev Loss = 23.979675483432015\n",
      "Epoch 13200: Train Loss = 86.71333461133995, Dev Loss = 23.9787960468065\n",
      "Epoch 13300: Train Loss = 86.68681998043955, Dev Loss = 23.97732109299411\n",
      "Epoch 13400: Train Loss = 86.66121085223247, Dev Loss = 23.97636758646603\n",
      "Epoch 13500: Train Loss = 86.6363696700468, Dev Loss = 23.975569861130936\n",
      "Epoch 13600: Train Loss = 86.61204802109023, Dev Loss = 23.974921161972865\n",
      "Epoch 13700: Train Loss = 86.58814009324762, Dev Loss = 23.974323916364252\n",
      "Epoch 13800: Train Loss = 86.56467236597594, Dev Loss = 23.973046736987246\n",
      "Epoch 13900: Train Loss = 86.54169811028085, Dev Loss = 23.971610409217195\n",
      "Epoch 14000: Train Loss = 86.51927955439847, Dev Loss = 23.970401515868893\n",
      "Epoch 14100: Train Loss = 86.49716505720043, Dev Loss = 23.969002754779982\n",
      "Epoch 14200: Train Loss = 86.47546242741976, Dev Loss = 23.967000624689188\n",
      "Epoch 14300: Train Loss = 86.45291704935046, Dev Loss = 23.966086636698602\n",
      "Epoch 14400: Train Loss = 86.4298156109252, Dev Loss = 23.96620532046498\n",
      "Epoch 14500: Train Loss = 86.40692699532433, Dev Loss = 23.966429103460314\n",
      "Epoch 14600: Train Loss = 86.38547970461657, Dev Loss = 23.966219052490526\n",
      "Epoch 14700: Train Loss = 86.36339924572559, Dev Loss = 23.965641646466267\n",
      "Epoch 14800: Train Loss = 86.34167746422904, Dev Loss = 23.964952235667603\n",
      "Epoch 14900: Train Loss = 86.3203260901647, Dev Loss = 23.964019836816924\n",
      "Epoch 15000: Train Loss = 86.29923355742716, Dev Loss = 23.9625709759354\n",
      "Epoch 15100: Train Loss = 86.27844943312745, Dev Loss = 23.96106561443575\n",
      "Epoch 15200: Train Loss = 86.25635006154074, Dev Loss = 23.95913463661845\n",
      "Epoch 15300: Train Loss = 86.23327538142357, Dev Loss = 23.957191054940658\n",
      "Epoch 15400: Train Loss = 86.21028261951498, Dev Loss = 23.954940210750614\n",
      "Epoch 15500: Train Loss = 86.18709965482148, Dev Loss = 23.952757767962844\n",
      "Epoch 15600: Train Loss = 86.16387217338547, Dev Loss = 23.950362259627454\n",
      "Epoch 15700: Train Loss = 86.14110059169094, Dev Loss = 23.947952108014942\n",
      "Epoch 15800: Train Loss = 86.11865854654907, Dev Loss = 23.945883899613282\n",
      "Epoch 15900: Train Loss = 86.09714650367332, Dev Loss = 23.943691628961925\n",
      "Epoch 16000: Train Loss = 86.07620114697218, Dev Loss = 23.941604839513236\n",
      "Epoch 16100: Train Loss = 86.05541625245684, Dev Loss = 23.93973342527515\n",
      "Epoch 16200: Train Loss = 86.03469722039051, Dev Loss = 23.93795659892115\n",
      "Epoch 16300: Train Loss = 86.01423900873633, Dev Loss = 23.93647611115687\n",
      "Epoch 16400: Train Loss = 85.99341092834672, Dev Loss = 23.935198797595564\n",
      "Epoch 16500: Train Loss = 85.97166138556788, Dev Loss = 23.933518457883178\n",
      "Epoch 16600: Train Loss = 85.95088321191511, Dev Loss = 23.931218794737703\n",
      "Epoch 16700: Train Loss = 85.93055059673016, Dev Loss = 23.92846223807772\n",
      "Epoch 16800: Train Loss = 85.91048108206358, Dev Loss = 23.924826138596266\n",
      "Epoch 16900: Train Loss = 85.89071163095817, Dev Loss = 23.921019137294508\n",
      "Epoch 17000: Train Loss = 85.87113364102416, Dev Loss = 23.917556764938972\n",
      "Epoch 17100: Train Loss = 85.85162497220688, Dev Loss = 23.914491265704594\n",
      "Epoch 17200: Train Loss = 85.83245752100066, Dev Loss = 23.911283566592846\n",
      "Epoch 17300: Train Loss = 85.8135387371045, Dev Loss = 23.908090545108067\n",
      "Epoch 17400: Train Loss = 85.79485010048464, Dev Loss = 23.90481128501497\n",
      "Epoch 17500: Train Loss = 85.77642487061378, Dev Loss = 23.901701282753322\n",
      "Epoch 17600: Train Loss = 85.75832504411161, Dev Loss = 23.89845207384605\n",
      "Epoch 17700: Train Loss = 85.74048329911898, Dev Loss = 23.89534600437652\n",
      "Epoch 17800: Train Loss = 85.722897642995, Dev Loss = 23.892426651971178\n",
      "Epoch 17900: Train Loss = 85.70520797348075, Dev Loss = 23.889353067510648\n",
      "Epoch 18000: Train Loss = 85.68770085366316, Dev Loss = 23.88650716666107\n",
      "Epoch 18100: Train Loss = 85.6701754278024, Dev Loss = 23.88385533158681\n",
      "Epoch 18200: Train Loss = 85.65276049841847, Dev Loss = 23.881338344270254\n",
      "Epoch 18300: Train Loss = 85.63588071703334, Dev Loss = 23.879790008392163\n",
      "Epoch 18400: Train Loss = 85.61832174125513, Dev Loss = 23.878784892052288\n",
      "Epoch 18500: Train Loss = 85.60055800775727, Dev Loss = 23.87728047114259\n",
      "Epoch 18600: Train Loss = 85.58242947367012, Dev Loss = 23.875395986303964\n",
      "Epoch 18700: Train Loss = 85.56464195280257, Dev Loss = 23.873302347788325\n",
      "Epoch 18800: Train Loss = 85.54710306519125, Dev Loss = 23.871255678046456\n",
      "Epoch 18900: Train Loss = 85.52972468340965, Dev Loss = 23.869194089336958\n",
      "Epoch 19000: Train Loss = 85.51255047293469, Dev Loss = 23.86710151130348\n",
      "Epoch 19100: Train Loss = 85.49543827440766, Dev Loss = 23.8647878919125\n",
      "Epoch 19200: Train Loss = 85.47753249444764, Dev Loss = 23.86352837356485\n",
      "Epoch 19300: Train Loss = 85.46039188708986, Dev Loss = 23.862455703986043\n",
      "Epoch 19400: Train Loss = 85.44368217318669, Dev Loss = 23.861510426513078\n",
      "Epoch 19500: Train Loss = 85.42712524577539, Dev Loss = 23.860388327766845\n",
      "Epoch 19600: Train Loss = 85.41075776452594, Dev Loss = 23.859248431683444\n",
      "Epoch 19700: Train Loss = 85.39472371453171, Dev Loss = 23.857860219438678\n",
      "Epoch 19800: Train Loss = 85.37892467602379, Dev Loss = 23.856639422144447\n",
      "Epoch 19900: Train Loss = 85.36338166886509, Dev Loss = 23.855347672480615\n",
      "Epoch 20000: Train Loss = 85.34807454317921, Dev Loss = 23.853835770791534\n",
      "Epoch 20100: Train Loss = 85.33288348363982, Dev Loss = 23.85254527263612\n",
      "Epoch 20200: Train Loss = 85.31795631139462, Dev Loss = 23.851204387759857\n",
      "Epoch 20300: Train Loss = 85.30335329736673, Dev Loss = 23.84969582185936\n",
      "Epoch 20400: Train Loss = 85.28920612377966, Dev Loss = 23.847822010637437\n",
      "Epoch 20500: Train Loss = 85.2751789423481, Dev Loss = 23.846096077271028\n",
      "Epoch 20600: Train Loss = 85.26126769564196, Dev Loss = 23.84435042496988\n",
      "Epoch 20700: Train Loss = 85.24754266462402, Dev Loss = 23.84265242012269\n",
      "Epoch 20800: Train Loss = 85.23400454609998, Dev Loss = 23.84114824349669\n",
      "Epoch 20900: Train Loss = 85.22060866039277, Dev Loss = 23.83966821800816\n",
      "Epoch 21000: Train Loss = 85.20744214457898, Dev Loss = 23.838680712051705\n",
      "Epoch 21100: Train Loss = 85.19450786928942, Dev Loss = 23.837831556014372\n",
      "Epoch 21200: Train Loss = 85.18192406599931, Dev Loss = 23.83706553448705\n",
      "Epoch 21300: Train Loss = 85.16948771674612, Dev Loss = 23.836372681123844\n",
      "Epoch 21400: Train Loss = 85.15710936187149, Dev Loss = 23.835784996777836\n",
      "Epoch 21500: Train Loss = 85.14486749566916, Dev Loss = 23.835122203671883\n",
      "Epoch 21600: Train Loss = 85.13276656341156, Dev Loss = 23.83444455216197\n",
      "Epoch 21700: Train Loss = 85.12077178096553, Dev Loss = 23.833815779287995\n",
      "Epoch 21800: Train Loss = 85.10775677240373, Dev Loss = 23.834106975440367\n",
      "Epoch 21900: Train Loss = 85.09489929989931, Dev Loss = 23.834425953316423\n",
      "Epoch 22000: Train Loss = 85.08213278062607, Dev Loss = 23.834382962301113\n",
      "Epoch 22100: Train Loss = 85.06943690751051, Dev Loss = 23.834223832646774\n",
      "Epoch 22200: Train Loss = 85.05691666704053, Dev Loss = 23.834007428655504\n",
      "Epoch 22300: Train Loss = 85.04453287003787, Dev Loss = 23.833738498749227\n",
      "Epoch 22400: Train Loss = 85.03189079774091, Dev Loss = 23.8332417504202\n",
      "Epoch 22500: Train Loss = 85.01868524709113, Dev Loss = 23.832942225775184\n",
      "Epoch 22600: Train Loss = 85.00548991076852, Dev Loss = 23.832288159685323\n",
      "Epoch 22700: Train Loss = 84.99192785152056, Dev Loss = 23.83167823651294\n",
      "Epoch 22800: Train Loss = 84.97868435705729, Dev Loss = 23.830929983812833\n",
      "Epoch 22900: Train Loss = 84.96538753374026, Dev Loss = 23.829725333518365\n",
      "Epoch 23000: Train Loss = 84.95215397831623, Dev Loss = 23.828569799194902\n",
      "Epoch 23100: Train Loss = 84.93873865790178, Dev Loss = 23.827354790610524\n",
      "Epoch 23200: Train Loss = 84.92494675606554, Dev Loss = 23.82619535298089\n",
      "Epoch 23300: Train Loss = 84.90984637778516, Dev Loss = 23.82534479064996\n",
      "Epoch 23400: Train Loss = 84.89494182615451, Dev Loss = 23.82388575079514\n",
      "Epoch 23500: Train Loss = 84.88046885654542, Dev Loss = 23.822500672755748\n",
      "Epoch 23600: Train Loss = 84.86601950667045, Dev Loss = 23.82097850734625\n",
      "Epoch 23700: Train Loss = 84.85171696583154, Dev Loss = 23.819411487681883\n",
      "Epoch 23800: Train Loss = 84.83754186644953, Dev Loss = 23.81776691705341\n",
      "Epoch 23900: Train Loss = 84.82346828462568, Dev Loss = 23.8160282994186\n",
      "Epoch 24000: Train Loss = 84.80953697976176, Dev Loss = 23.814358875247233\n",
      "Epoch 24100: Train Loss = 84.79573648014775, Dev Loss = 23.81263113126063\n",
      "Epoch 24200: Train Loss = 84.78198964238945, Dev Loss = 23.81064248370568\n",
      "Epoch 24300: Train Loss = 84.76834886527347, Dev Loss = 23.808635856897496\n",
      "Epoch 24400: Train Loss = 84.75483542167103, Dev Loss = 23.807272289176083\n",
      "Epoch 24500: Train Loss = 84.7414629844557, Dev Loss = 23.80587572728699\n",
      "Epoch 24600: Train Loss = 84.72818814225573, Dev Loss = 23.80473627026529\n",
      "Epoch 24700: Train Loss = 84.71504658373779, Dev Loss = 23.80331674601608\n",
      "Epoch 24800: Train Loss = 84.70295843582483, Dev Loss = 23.801878367699924\n",
      "Epoch 24900: Train Loss = 84.69171955457941, Dev Loss = 23.80085486498938\n",
      "Epoch 25000: Train Loss = 84.68008874426789, Dev Loss = 23.79940616297269\n",
      "Epoch 25100: Train Loss = 84.66857212411992, Dev Loss = 23.797877088475538\n",
      "Epoch 25200: Train Loss = 84.65709838365208, Dev Loss = 23.796021699318214\n",
      "Epoch 25300: Train Loss = 84.64572552364035, Dev Loss = 23.794418280032247\n",
      "Epoch 25400: Train Loss = 84.63456764292604, Dev Loss = 23.792167525645347\n",
      "Epoch 25500: Train Loss = 84.62354067848378, Dev Loss = 23.789781693013538\n",
      "Epoch 25600: Train Loss = 84.61259558101389, Dev Loss = 23.788164258597572\n",
      "Epoch 25700: Train Loss = 84.6018496966272, Dev Loss = 23.786737737159605\n",
      "Epoch 25800: Train Loss = 84.59120810649037, Dev Loss = 23.785546675457635\n",
      "Epoch 25900: Train Loss = 84.58067359972395, Dev Loss = 23.784317599572915\n",
      "Epoch 26000: Train Loss = 84.57020861035772, Dev Loss = 23.78312062723166\n",
      "Epoch 26100: Train Loss = 84.55984049649663, Dev Loss = 23.781972541423468\n",
      "Epoch 26200: Train Loss = 84.5495642559392, Dev Loss = 23.780682753271762\n",
      "Epoch 26300: Train Loss = 84.53936222931014, Dev Loss = 23.77972086169319\n",
      "Epoch 26400: Train Loss = 84.52922993697146, Dev Loss = 23.77886988788499\n",
      "Epoch 26500: Train Loss = 84.51917749730788, Dev Loss = 23.77787498116321\n",
      "Epoch 26600: Train Loss = 84.50922226797105, Dev Loss = 23.776858985027044\n",
      "Epoch 26700: Train Loss = 84.49931846928456, Dev Loss = 23.775950782502974\n",
      "Epoch 26800: Train Loss = 84.4894923927944, Dev Loss = 23.774929087648676\n",
      "Epoch 26900: Train Loss = 84.47953603706355, Dev Loss = 23.774150775696143\n",
      "Epoch 27000: Train Loss = 84.46965237405944, Dev Loss = 23.773371148461784\n",
      "Epoch 27100: Train Loss = 84.45982292168944, Dev Loss = 23.77247671468081\n",
      "Epoch 27200: Train Loss = 84.45004857768647, Dev Loss = 23.77169733542963\n",
      "Epoch 27300: Train Loss = 84.44035197897277, Dev Loss = 23.77085917589381\n",
      "Epoch 27400: Train Loss = 84.43071319785622, Dev Loss = 23.77002746543946\n",
      "Epoch 27500: Train Loss = 84.42114066110042, Dev Loss = 23.769142438548542\n",
      "Epoch 27600: Train Loss = 84.41163459122815, Dev Loss = 23.76838007851388\n",
      "Epoch 27700: Train Loss = 84.40208458429962, Dev Loss = 23.76764175399026\n",
      "Epoch 27800: Train Loss = 84.39241793678858, Dev Loss = 23.767118884538238\n",
      "Epoch 27900: Train Loss = 84.38217523424386, Dev Loss = 23.766770175531217\n",
      "Epoch 28000: Train Loss = 84.37182508285922, Dev Loss = 23.766567834761304\n",
      "Epoch 28100: Train Loss = 84.36156198345546, Dev Loss = 23.766348759648643\n",
      "Epoch 28200: Train Loss = 84.35139546142825, Dev Loss = 23.76600737505352\n",
      "Epoch 28300: Train Loss = 84.3413010332504, Dev Loss = 23.765793873644608\n",
      "Epoch 28400: Train Loss = 84.33127257122199, Dev Loss = 23.765632268475674\n",
      "Epoch 28500: Train Loss = 84.32157322650097, Dev Loss = 23.76526936106312\n",
      "Epoch 28600: Train Loss = 84.31212791524868, Dev Loss = 23.76520324944079\n",
      "Epoch 28700: Train Loss = 84.30278203935845, Dev Loss = 23.765311782176937\n",
      "Epoch 28800: Train Loss = 84.29350622162272, Dev Loss = 23.76527274110049\n",
      "Epoch 28900: Train Loss = 84.28430133072052, Dev Loss = 23.765321364051943\n",
      "Epoch 29000: Train Loss = 84.27517480243756, Dev Loss = 23.765503978721014\n",
      "Epoch 29100: Train Loss = 84.2661795441777, Dev Loss = 23.76583811940406\n",
      "Epoch 29200: Train Loss = 84.25629547806871, Dev Loss = 23.76656849114356\n",
      "Epoch 29300: Train Loss = 84.24607278808956, Dev Loss = 23.7674378805849\n",
      "Epoch 29400: Train Loss = 84.23630172587298, Dev Loss = 23.768384624222907\n",
      "Epoch 29500: Train Loss = 84.22710819954335, Dev Loss = 23.769149182789658\n",
      "Epoch 29600: Train Loss = 84.21885662984789, Dev Loss = 23.769370685311323\n",
      "Epoch 29700: Train Loss = 84.2105859538826, Dev Loss = 23.76943494755828\n",
      "Epoch 29800: Train Loss = 84.20237429052969, Dev Loss = 23.769503597198025\n",
      "Epoch 29900: Train Loss = 84.19422176046574, Dev Loss = 23.769495547511767\n",
      "Epoch 30000: Train Loss = 84.18614067968164, Dev Loss = 23.769655942521247\n",
      "Epoch 30100: Train Loss = 84.1781236664635, Dev Loss = 23.769629534219582\n",
      "Epoch 30200: Train Loss = 84.17011379035473, Dev Loss = 23.769702696499323\n",
      "Epoch 30300: Train Loss = 84.1623252073903, Dev Loss = 23.769667096036656\n",
      "Epoch 30400: Train Loss = 84.1545930409417, Dev Loss = 23.769783493883196\n",
      "Epoch 30500: Train Loss = 84.14676735582722, Dev Loss = 23.770274338860194\n",
      "Epoch 30600: Train Loss = 84.13899344998569, Dev Loss = 23.770674590328877\n",
      "Epoch 30700: Train Loss = 84.13136817874559, Dev Loss = 23.770605207688007\n",
      "Epoch 30800: Train Loss = 84.12391453998848, Dev Loss = 23.770060231400844\n",
      "Epoch 30900: Train Loss = 84.11647375900685, Dev Loss = 23.76940495357784\n",
      "Epoch 31000: Train Loss = 84.10916991687009, Dev Loss = 23.769123367148136\n",
      "Epoch 31100: Train Loss = 84.10195638485683, Dev Loss = 23.768904701758437\n",
      "Epoch 31200: Train Loss = 84.09475603223358, Dev Loss = 23.768771976440867\n",
      "Epoch 31300: Train Loss = 84.08761779459704, Dev Loss = 23.76854241826227\n",
      "Epoch 31400: Train Loss = 84.08054818989223, Dev Loss = 23.76825737558822\n",
      "Epoch 31500: Train Loss = 84.07354779967378, Dev Loss = 23.767852745071625\n",
      "Epoch 31600: Train Loss = 84.0665412906702, Dev Loss = 23.767554498743014\n",
      "Epoch 31700: Train Loss = 84.0593368215907, Dev Loss = 23.76732583346792\n",
      "Epoch 31800: Train Loss = 84.05212099421009, Dev Loss = 23.76715908986794\n",
      "Epoch 31900: Train Loss = 84.04498068485779, Dev Loss = 23.766958995521648\n",
      "Epoch 32000: Train Loss = 84.03785062303086, Dev Loss = 23.76684500767283\n",
      "Epoch 32100: Train Loss = 84.03075616864189, Dev Loss = 23.76669319543221\n",
      "Epoch 32200: Train Loss = 84.02373570595424, Dev Loss = 23.766419857703394\n",
      "Epoch 32300: Train Loss = 84.01671434267735, Dev Loss = 23.766207333810314\n",
      "Epoch 32400: Train Loss = 84.00978237071268, Dev Loss = 23.766044564266913\n",
      "Epoch 32500: Train Loss = 84.00288445946813, Dev Loss = 23.765946925553138\n",
      "Epoch 32600: Train Loss = 83.99605875563226, Dev Loss = 23.765800960092143\n",
      "Epoch 32700: Train Loss = 83.98926918977182, Dev Loss = 23.765758693229067\n",
      "Epoch 32800: Train Loss = 83.98252953003337, Dev Loss = 23.76562601692683\n",
      "Epoch 32900: Train Loss = 83.97581480830507, Dev Loss = 23.76555886206898\n",
      "Epoch 33000: Train Loss = 83.96915272742132, Dev Loss = 23.76537129722881\n",
      "Epoch 33100: Train Loss = 83.96252139300108, Dev Loss = 23.765340632121024\n",
      "Epoch 33200: Train Loss = 83.95590406319374, Dev Loss = 23.765209660581196\n",
      "Epoch 33300: Train Loss = 83.9493012853871, Dev Loss = 23.765364712002942\n",
      "Epoch 33400: Train Loss = 83.94273843031264, Dev Loss = 23.765505863313386\n",
      "Epoch 33500: Train Loss = 83.93620606575723, Dev Loss = 23.765598180250272\n",
      "Epoch 33600: Train Loss = 83.92971326159383, Dev Loss = 23.765732030462818\n",
      "Epoch 33700: Train Loss = 83.92325214397316, Dev Loss = 23.765839909433133\n",
      "Epoch 33800: Train Loss = 83.91681552090944, Dev Loss = 23.765976349553686\n",
      "Epoch 33900: Train Loss = 83.91041951869933, Dev Loss = 23.76604692640986\n",
      "Epoch 34000: Train Loss = 83.90409503824631, Dev Loss = 23.766231844955644\n",
      "Epoch 34100: Train Loss = 83.89780670430164, Dev Loss = 23.766386117340467\n",
      "Epoch 34200: Train Loss = 83.89159772605561, Dev Loss = 23.766624167463227\n",
      "Epoch 34300: Train Loss = 83.88542443876763, Dev Loss = 23.766970758615713\n",
      "Epoch 34400: Train Loss = 83.87929181860194, Dev Loss = 23.76747835132654\n",
      "Epoch 34500: Train Loss = 83.87317642991474, Dev Loss = 23.76784743498669\n",
      "Epoch 34600: Train Loss = 83.86708053628728, Dev Loss = 23.76819941758027\n",
      "Epoch 34700: Train Loss = 83.86100751928359, Dev Loss = 23.768639058539428\n",
      "Epoch 34800: Train Loss = 83.85495684669229, Dev Loss = 23.769022138057075\n",
      "Epoch 34900: Train Loss = 83.8489037860363, Dev Loss = 23.769518372982343\n",
      "Epoch 35000: Train Loss = 83.84208677176196, Dev Loss = 23.77061494991612\n",
      "Epoch 35100: Train Loss = 83.83509544171741, Dev Loss = 23.771530852169676\n",
      "Epoch 35200: Train Loss = 83.82674988774875, Dev Loss = 23.772077252240972\n",
      "Epoch 35300: Train Loss = 83.818407787716, Dev Loss = 23.77261547500391\n",
      "Epoch 35400: Train Loss = 83.81017025312485, Dev Loss = 23.77302796319959\n",
      "Epoch 35500: Train Loss = 83.80198223400168, Dev Loss = 23.773357782020767\n",
      "Epoch 35600: Train Loss = 83.79384395218526, Dev Loss = 23.773770292044595\n",
      "Epoch 35700: Train Loss = 83.78577086077266, Dev Loss = 23.774131639277684\n",
      "Epoch 35800: Train Loss = 83.77773990725586, Dev Loss = 23.774457772409143\n",
      "Epoch 35900: Train Loss = 83.7697735251196, Dev Loss = 23.774833646158797\n",
      "Epoch 36000: Train Loss = 83.76183019884776, Dev Loss = 23.775221283244424\n",
      "Epoch 36100: Train Loss = 83.75394733458882, Dev Loss = 23.775524069703447\n",
      "Epoch 36200: Train Loss = 83.74612190693932, Dev Loss = 23.775553743719538\n",
      "Epoch 36300: Train Loss = 83.73833358944768, Dev Loss = 23.7755662520391\n",
      "Epoch 36400: Train Loss = 83.73054962354519, Dev Loss = 23.775394737277157\n",
      "Epoch 36500: Train Loss = 83.72305365790925, Dev Loss = 23.775333803182335\n",
      "Epoch 36600: Train Loss = 83.71605854137457, Dev Loss = 23.77532510191268\n",
      "Epoch 36700: Train Loss = 83.70910749948752, Dev Loss = 23.775389040124303\n",
      "Epoch 36800: Train Loss = 83.70221784895924, Dev Loss = 23.775470330490826\n",
      "Epoch 36900: Train Loss = 83.69535439002487, Dev Loss = 23.775572572142146\n",
      "Epoch 37000: Train Loss = 83.68851979589523, Dev Loss = 23.775712909624836\n",
      "Epoch 37100: Train Loss = 83.68171249031994, Dev Loss = 23.775751482450108\n",
      "Epoch 37200: Train Loss = 83.67494126731722, Dev Loss = 23.77586033972778\n",
      "Epoch 37300: Train Loss = 83.66822883385045, Dev Loss = 23.775813547029294\n",
      "Epoch 37400: Train Loss = 83.66162556666843, Dev Loss = 23.775722173455627\n",
      "Epoch 37500: Train Loss = 83.65509148518218, Dev Loss = 23.77552182784079\n",
      "Epoch 37600: Train Loss = 83.6485986273322, Dev Loss = 23.775352162666934\n",
      "Epoch 37700: Train Loss = 83.64219242320164, Dev Loss = 23.7751769501501\n",
      "Epoch 37800: Train Loss = 83.63584054075295, Dev Loss = 23.77505830142185\n",
      "Epoch 37900: Train Loss = 83.62953201350189, Dev Loss = 23.774910249767306\n",
      "Epoch 38000: Train Loss = 83.62326298321733, Dev Loss = 23.774709901338433\n",
      "Epoch 38100: Train Loss = 83.61715953877751, Dev Loss = 23.774463973766064\n",
      "Epoch 38200: Train Loss = 83.611076097369, Dev Loss = 23.77422766270981\n",
      "Epoch 38300: Train Loss = 83.60500310051697, Dev Loss = 23.773842828986098\n",
      "Epoch 38400: Train Loss = 83.59894536088015, Dev Loss = 23.773451376935128\n",
      "Epoch 38500: Train Loss = 83.59290679211263, Dev Loss = 23.773163612518868\n",
      "Epoch 38600: Train Loss = 83.58690953979232, Dev Loss = 23.772670680019747\n",
      "Epoch 38700: Train Loss = 83.58093956661612, Dev Loss = 23.772280085816966\n",
      "Epoch 38800: Train Loss = 83.57501190739342, Dev Loss = 23.77179870046556\n",
      "Epoch 38900: Train Loss = 83.56910773226704, Dev Loss = 23.77127027876486\n",
      "Epoch 39000: Train Loss = 83.56319705432122, Dev Loss = 23.770847602977163\n",
      "Epoch 39100: Train Loss = 83.55732580483874, Dev Loss = 23.770291477614993\n",
      "Epoch 39200: Train Loss = 83.55146137344974, Dev Loss = 23.76966618210067\n",
      "Epoch 39300: Train Loss = 83.5456167801207, Dev Loss = 23.76916184326638\n",
      "Epoch 39400: Train Loss = 83.5397197088118, Dev Loss = 23.768727472121554\n",
      "Epoch 39500: Train Loss = 83.53386488255366, Dev Loss = 23.768333694930377\n",
      "Epoch 39600: Train Loss = 83.52803055987987, Dev Loss = 23.76811235989156\n",
      "Epoch 39700: Train Loss = 83.52222063448261, Dev Loss = 23.767913122515736\n",
      "Epoch 39800: Train Loss = 83.51615060110748, Dev Loss = 23.7677817337463\n",
      "Epoch 39900: Train Loss = 83.51005936946676, Dev Loss = 23.767632737345753\n",
      "Epoch 40000: Train Loss = 83.50401558643993, Dev Loss = 23.767552891025836\n",
      "Epoch 40100: Train Loss = 83.49798417739986, Dev Loss = 23.767464567665844\n",
      "Epoch 40200: Train Loss = 83.49200007489227, Dev Loss = 23.7673438260013\n",
      "Epoch 40300: Train Loss = 83.48601292146196, Dev Loss = 23.767290619429595\n",
      "Epoch 40400: Train Loss = 83.47914242649642, Dev Loss = 23.768763501033334\n",
      "Epoch 40500: Train Loss = 83.47181120887338, Dev Loss = 23.77114933289517\n",
      "Epoch 40600: Train Loss = 83.46458186094375, Dev Loss = 23.773387563069335\n",
      "Epoch 40700: Train Loss = 83.45741456351689, Dev Loss = 23.775666440675845\n",
      "Epoch 40800: Train Loss = 83.45033628648828, Dev Loss = 23.77776804762373\n",
      "Epoch 40900: Train Loss = 83.44330473664655, Dev Loss = 23.780016661925426\n",
      "Epoch 41000: Train Loss = 83.43620395271537, Dev Loss = 23.78261594894019\n",
      "Epoch 41100: Train Loss = 83.42973123245693, Dev Loss = 23.78407402731586\n",
      "Epoch 41200: Train Loss = 83.42346598676514, Dev Loss = 23.785213336772067\n",
      "Epoch 41300: Train Loss = 83.41720315736083, Dev Loss = 23.786317782193038\n",
      "Epoch 41400: Train Loss = 83.41098115123705, Dev Loss = 23.787439154644172\n",
      "Epoch 41500: Train Loss = 83.40480857247793, Dev Loss = 23.788472106810993\n",
      "Epoch 41600: Train Loss = 83.39865796960862, Dev Loss = 23.789497781906427\n",
      "Epoch 41700: Train Loss = 83.39255519309643, Dev Loss = 23.790481224210108\n",
      "Epoch 41800: Train Loss = 83.38649757071911, Dev Loss = 23.791484158821344\n",
      "Epoch 41900: Train Loss = 83.380475264491, Dev Loss = 23.792572418680116\n",
      "Epoch 42000: Train Loss = 83.37448779247772, Dev Loss = 23.79357757072133\n",
      "Epoch 42100: Train Loss = 83.3685536597952, Dev Loss = 23.79460553338191\n",
      "Epoch 42200: Train Loss = 83.36266085299735, Dev Loss = 23.79558965776094\n",
      "Epoch 42300: Train Loss = 83.35679704029295, Dev Loss = 23.79659908488217\n",
      "Epoch 42400: Train Loss = 83.35097760084118, Dev Loss = 23.7975522554173\n",
      "Epoch 42500: Train Loss = 83.34517710776662, Dev Loss = 23.79838883487456\n",
      "Epoch 42600: Train Loss = 83.3394207276108, Dev Loss = 23.799316366545945\n",
      "Epoch 42700: Train Loss = 83.33366396863403, Dev Loss = 23.800210526373885\n",
      "Epoch 42800: Train Loss = 83.32793719632527, Dev Loss = 23.801017799253128\n",
      "Epoch 42900: Train Loss = 83.32222542096898, Dev Loss = 23.801865500773022\n",
      "Epoch 43000: Train Loss = 83.31655424258629, Dev Loss = 23.80274835803187\n",
      "Epoch 43100: Train Loss = 83.31092571890174, Dev Loss = 23.803549619070672\n",
      "Epoch 43200: Train Loss = 83.3053040408304, Dev Loss = 23.804433134910287\n",
      "Epoch 43300: Train Loss = 83.29971885886684, Dev Loss = 23.805201055588356\n",
      "Epoch 43400: Train Loss = 83.29418120803405, Dev Loss = 23.80599340198774\n",
      "Epoch 43500: Train Loss = 83.28872270739801, Dev Loss = 23.806832398194643\n",
      "Epoch 43600: Train Loss = 83.28325626126406, Dev Loss = 23.807595589891676\n",
      "Epoch 43700: Train Loss = 83.27781470687154, Dev Loss = 23.808333811864365\n",
      "Epoch 43800: Train Loss = 83.27244958041335, Dev Loss = 23.80896533260023\n",
      "Epoch 43900: Train Loss = 83.26712244080625, Dev Loss = 23.809491781988363\n",
      "Epoch 44000: Train Loss = 83.2619428593515, Dev Loss = 23.809779613816005\n",
      "Epoch 44100: Train Loss = 83.25667060528781, Dev Loss = 23.809997775432333\n",
      "Epoch 44200: Train Loss = 83.25133265117341, Dev Loss = 23.810243695620148\n",
      "Epoch 44300: Train Loss = 83.24601485206388, Dev Loss = 23.81036959312464\n",
      "Epoch 44400: Train Loss = 83.24073088236378, Dev Loss = 23.81041416829757\n",
      "Epoch 44500: Train Loss = 83.23544184353689, Dev Loss = 23.81041169798805\n",
      "Epoch 44600: Train Loss = 83.2301070650048, Dev Loss = 23.81018961419162\n",
      "Epoch 44700: Train Loss = 83.22433517168773, Dev Loss = 23.80883259561026\n",
      "Epoch 44800: Train Loss = 83.21848016806105, Dev Loss = 23.80771006076492\n",
      "Epoch 44900: Train Loss = 83.21268293128239, Dev Loss = 23.806703967092687\n",
      "Epoch 45000: Train Loss = 83.2070008759319, Dev Loss = 23.805643387619845\n",
      "Epoch 45100: Train Loss = 83.20132263561435, Dev Loss = 23.80446779431031\n",
      "Epoch 45200: Train Loss = 83.19531698938252, Dev Loss = 23.80352446436838\n",
      "Epoch 45300: Train Loss = 83.18920017536749, Dev Loss = 23.80290541851089\n",
      "Epoch 45400: Train Loss = 83.18316568553695, Dev Loss = 23.802411146560416\n",
      "Epoch 45500: Train Loss = 83.17719419818813, Dev Loss = 23.801855003317346\n",
      "Epoch 45600: Train Loss = 83.17125505396898, Dev Loss = 23.80131585675479\n",
      "Epoch 45700: Train Loss = 83.16537402172142, Dev Loss = 23.800561772115337\n",
      "Epoch 45800: Train Loss = 83.1595415951626, Dev Loss = 23.79975314705905\n",
      "Epoch 45900: Train Loss = 83.15370709189085, Dev Loss = 23.79897776513601\n",
      "Epoch 46000: Train Loss = 83.14788370858355, Dev Loss = 23.79827530107555\n",
      "Epoch 46100: Train Loss = 83.14210152238405, Dev Loss = 23.797507771725552\n",
      "Epoch 46200: Train Loss = 83.136368198344, Dev Loss = 23.796902632187194\n",
      "Epoch 46300: Train Loss = 83.13066173331447, Dev Loss = 23.796367825678136\n",
      "Epoch 46400: Train Loss = 83.12497275485131, Dev Loss = 23.795889336888465\n",
      "Epoch 46500: Train Loss = 83.11928452042463, Dev Loss = 23.795334409737965\n",
      "Epoch 46600: Train Loss = 83.11360217134758, Dev Loss = 23.79480162745358\n",
      "Epoch 46700: Train Loss = 83.10794207519199, Dev Loss = 23.79424696487182\n",
      "Epoch 46800: Train Loss = 83.10235261989646, Dev Loss = 23.793693006900824\n",
      "Epoch 46900: Train Loss = 83.09678511946981, Dev Loss = 23.793240276224545\n",
      "Epoch 47000: Train Loss = 83.09119297072834, Dev Loss = 23.79279169053531\n",
      "Epoch 47100: Train Loss = 83.08564918151927, Dev Loss = 23.792150193900987\n",
      "Epoch 47200: Train Loss = 83.08042781145632, Dev Loss = 23.79148388198722\n",
      "Epoch 47300: Train Loss = 83.07525729070724, Dev Loss = 23.7909015297055\n",
      "Epoch 47400: Train Loss = 83.07010088899995, Dev Loss = 23.790291207588346\n",
      "Epoch 47500: Train Loss = 83.06497632569426, Dev Loss = 23.789682040733748\n",
      "Epoch 47600: Train Loss = 83.05984200375235, Dev Loss = 23.78910782879244\n",
      "Epoch 47700: Train Loss = 83.05474716625585, Dev Loss = 23.788548618673136\n",
      "Epoch 47800: Train Loss = 83.04968561839004, Dev Loss = 23.787919425022395\n",
      "Epoch 47900: Train Loss = 83.04463055823872, Dev Loss = 23.787343841024676\n",
      "Epoch 48000: Train Loss = 83.03958532385997, Dev Loss = 23.786795017865632\n",
      "Epoch 48100: Train Loss = 83.03456839861808, Dev Loss = 23.78617389339228\n",
      "Epoch 48200: Train Loss = 83.02956882131045, Dev Loss = 23.78564795226221\n",
      "Epoch 48300: Train Loss = 83.02455871438985, Dev Loss = 23.785033794032707\n",
      "Epoch 48400: Train Loss = 83.01935322080716, Dev Loss = 23.78463823759215\n",
      "Epoch 48500: Train Loss = 83.0141173518561, Dev Loss = 23.784330134824724\n",
      "Epoch 48600: Train Loss = 83.00883308610207, Dev Loss = 23.7840822320013\n",
      "Epoch 48700: Train Loss = 83.00357752078085, Dev Loss = 23.783759278391205\n",
      "Epoch 48800: Train Loss = 82.99837749063954, Dev Loss = 23.783647170288795\n",
      "Epoch 48900: Train Loss = 82.99324087747121, Dev Loss = 23.783511350522065\n",
      "Epoch 49000: Train Loss = 82.98811959636255, Dev Loss = 23.78343495950756\n",
      "Epoch 49100: Train Loss = 82.98302793534965, Dev Loss = 23.783279524961344\n",
      "Epoch 49200: Train Loss = 82.97796159523658, Dev Loss = 23.78312602259049\n",
      "Epoch 49300: Train Loss = 82.97288956101303, Dev Loss = 23.78282591703409\n",
      "Epoch 49400: Train Loss = 82.96775967958382, Dev Loss = 23.782476799205046\n",
      "Epoch 49500: Train Loss = 82.96264738885776, Dev Loss = 23.782102295268547\n",
      "Epoch 49600: Train Loss = 82.95755335741053, Dev Loss = 23.781730022921728\n",
      "Epoch 49700: Train Loss = 82.95248326554089, Dev Loss = 23.781416917943456\n",
      "Epoch 49800: Train Loss = 82.94742650651563, Dev Loss = 23.78113772529209\n",
      "Epoch 49900: Train Loss = 82.94238688069078, Dev Loss = 23.780891185364815\n"
     ]
    }
   ],
   "source": [
    "train_loss, dev_loss = model_train(model=Classifier_model_2, learning_rate=0.5, num_epochs=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d69838d3a0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, c='r')\n",
    "plt.plot(range(1,50001, 100), dev_loss, c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, pred = Classifier_model_2.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.857142857142857)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum(np.where(np.argmax(Y_test, axis=0, keepdims=True) == np.argmax(pred, axis=0, keepdims=True)))/Y_test.shape[1]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d6983f8f20>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.argmax(Y_test,axis=0, keepdims=True).flatten()\n",
    "plt.scatter(range(len(data)), data, c=\"b\")  # Scatter plot\n",
    "plt.scatter(range(len(pred)), pred.flatten(), c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and grads of trained model(without weighted class implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW4\n",
      "[[ 2.01504190e-06 -3.48473762e-04  1.02022836e-02  9.23263179e-03\n",
      "   9.87900222e-03]\n",
      " [-2.24110492e-04 -2.51867299e-04 -1.05753910e-02 -1.02577598e-03\n",
      "   5.99526606e-03]\n",
      " [-4.40871014e-05 -1.39602903e-04 -3.96262841e-03 -3.22194904e-03\n",
      "  -9.12903875e-03]\n",
      " [ 2.66182552e-04  7.39943963e-04  4.33573582e-03 -4.98490677e-03\n",
      "  -6.74522953e-03]]\n",
      "db4\n",
      "[[-0.02873701]\n",
      " [ 0.01278061]\n",
      " [ 0.01676087]\n",
      " [-0.00080446]]\n",
      "dW3\n",
      "[[ 2.82535187e-04 -1.82267217e-04 -2.10375497e-04  5.67155050e-04\n",
      "   2.16404360e-04]\n",
      " [-8.70812269e-05  9.67615125e-05  6.50029106e-05 -4.29454541e-05\n",
      "   1.36755831e-04]\n",
      " [-8.29532024e-03 -3.99176666e-03  8.33418065e-04  3.04582140e-03\n",
      "   7.01222395e-04]\n",
      " [-6.04643461e-03 -2.11715246e-03  2.81110577e-04 -8.46155842e-03\n",
      "   3.89147462e-03]\n",
      " [-1.48634456e-04  7.38510088e-03  4.88027190e-03 -6.89610935e-03\n",
      "  -1.10334242e-03]]\n",
      "db3\n",
      "[[-0.00035471]\n",
      " [ 0.00016139]\n",
      " [-0.00247964]\n",
      " [-0.00333976]\n",
      " [ 0.00456718]]\n",
      "dW2\n",
      "[[-4.75770134e-04 -6.83019805e-03 -7.30213795e-03 -8.25851621e-05\n",
      "  -7.27248533e-04]\n",
      " [-2.36789647e-03 -4.67237226e-03  4.28268246e-03  2.56023697e-03\n",
      "   2.63409473e-03]\n",
      " [-2.44143214e-04 -1.40590500e-03  2.48828645e-03  2.58939399e-03\n",
      "  -1.89793984e-03]\n",
      " [-3.44487391e-03 -1.79686863e-03  1.73589756e-02 -1.14119950e-03\n",
      "   4.70627952e-03]\n",
      " [ 3.97162568e-03 -2.74934149e-03 -4.34354149e-03 -1.70711220e-04\n",
      "  -1.63851769e-03]]\n",
      "db2\n",
      "[[-0.01141633]\n",
      " [-0.0053501 ]\n",
      " [-0.00097117]\n",
      " [ 0.00496208]\n",
      " [ 0.00289452]]\n",
      "dW1\n",
      "[[-1.96402659e-03  6.47383734e-05 -4.34639914e-03  7.25670681e-04\n",
      "   1.64973946e-03 -3.58549900e-03  2.51864998e-03  7.91555524e-03\n",
      "  -1.82294054e-03 -3.23003628e-04  3.62085978e-04 -5.43174060e-03\n",
      "   2.39698736e-03  4.12660155e-05  1.24558517e-02  3.51829915e-03\n",
      "   2.13605134e-03  1.97918024e-03  3.94279274e-03  8.73454238e-03]\n",
      " [ 1.98288889e-03 -1.71187717e-03 -2.81494507e-03 -2.95407340e-03\n",
      "  -2.91828283e-05 -5.72669028e-03 -4.81418127e-03 -3.91592440e-03\n",
      "  -3.54422895e-03 -3.37470061e-03  8.87768302e-03 -9.06542572e-03\n",
      "   4.35742294e-03  4.13850507e-04  1.29567524e-03  3.52631841e-03\n",
      "  -4.93358574e-03 -4.81374409e-03 -6.01932275e-03  9.85897512e-03]\n",
      " [ 3.24661760e-03 -2.31224860e-03  4.55664594e-04 -1.43917721e-03\n",
      "  -4.69274885e-04 -3.02368537e-03 -5.25483790e-04  1.03106560e-03\n",
      "   9.72411933e-03 -7.84384979e-04 -1.97020005e-03  2.43289747e-03\n",
      "   4.61872751e-03 -7.50461069e-03  9.16836241e-04  8.78218074e-03\n",
      "   2.93918137e-03  2.67038788e-03  4.49607401e-03 -8.49296318e-03]\n",
      " [ 4.49588239e-03  1.31934515e-03  2.26573777e-03  1.72439047e-03\n",
      "   4.96866919e-03  7.21939537e-04  9.05490836e-03  9.82346585e-03\n",
      "   2.66716516e-04 -6.86518258e-03 -2.26213717e-03 -7.95436143e-03\n",
      "   4.24171620e-03 -6.70835832e-04 -4.09985099e-03 -1.09071870e-02\n",
      "  -1.20128854e-03 -1.15829550e-03 -1.12815511e-03  8.32903362e-03]\n",
      " [-4.40296664e-03 -4.95326898e-04  1.66956233e-03 -6.39205657e-04\n",
      "   2.67188445e-04  2.52209812e-03 -3.07973445e-03 -4.19083672e-03\n",
      "  -3.23049922e-04  2.69906469e-04  1.18765956e-03 -1.53483564e-03\n",
      "  -2.58894397e-03 -1.58053322e-03  5.74501952e-03 -8.54051569e-03\n",
      "   2.18664629e-03  2.11567020e-03  1.30211158e-03  2.34854354e-03]]\n",
      "db1\n",
      "[[-0.00183086]\n",
      " [-0.00054295]\n",
      " [-0.00083181]\n",
      " [ 0.00025099]\n",
      " [ 0.00228925]]\n"
     ]
    }
   ],
   "source": [
    "for i in Classifier_model_1.grads:\n",
    "    print(i)\n",
    "    print(Classifier_model_1.grads[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1\n",
      "[[ 0.14448878  0.1427592  -0.22332228  1.02302673 -0.00589812  0.43139844\n",
      "   0.07319129 -0.21108059  0.03956437 -0.41510724  0.09040594  0.173129\n",
      "  -0.11131797  0.05695355  0.30423073  0.32225965  0.25958659 -0.04744521\n",
      "  -0.27257901 -0.43081433]\n",
      " [-0.51044321  0.38090731  0.19958137  0.30665433  0.19651055 -0.20386264\n",
      "   0.29507758  0.29732358  0.22715133 -0.10740794  0.0862672   0.59409723\n",
      "   0.06147589  0.2747375   0.02716567  0.36893706  0.0448015  -0.42922307\n",
      "  -0.03510693 -0.14604511]\n",
      " [-0.32092906 -0.21061961  0.11469365 -0.35676392  0.03008718  0.31446925\n",
      "   0.11844025 -0.15019763  0.09758666 -0.25685829 -0.74414564 -0.29064871\n",
      "   0.74674313 -0.09372945 -0.71901868 -0.56642784  0.34816881 -0.04707945\n",
      "   0.13722243  0.33026743]\n",
      " [ 0.24405848  0.71821501  0.00698488  0.13221419 -0.02443976 -0.34765159\n",
      "  -0.00885515 -0.03255912 -0.32376684 -0.3417988  -0.57452734  0.65904555\n",
      "   0.86952684  0.22189875 -0.23956448  0.504087    0.2620643  -0.2137421\n",
      "   0.20353812 -0.39711954]\n",
      " [-0.32979279 -0.21232865 -0.06749891 -0.41343596 -0.32650594 -0.46911578\n",
      "  -0.21572977  0.27488399 -0.03042475 -0.83767464  0.25265665 -0.56929584\n",
      "   0.20700269  0.1627081   0.10406814  0.39872782  0.43176251 -0.043087\n",
      "   0.05876892 -0.08881196]]\n",
      "b1\n",
      "[[-0.05478663]\n",
      " [ 0.07615971]\n",
      " [ 0.1171627 ]\n",
      " [ 0.0925117 ]\n",
      " [ 0.00483743]]\n",
      "W2\n",
      "[[ 0.87616422  0.61536468  0.61544949  0.96280704 -1.49367422]\n",
      " [-0.36618859  0.92371301  0.35302445 -1.02174807  0.41453724]\n",
      " [ 0.22058497 -0.3310053  -0.70072629 -0.23536941  0.28093285]\n",
      " [ 0.59215496 -0.39866818  0.3336549   1.28427863 -0.47074111]\n",
      " [-0.1069234  -0.00465482  0.7360574  -0.27225186  0.84816554]]\n",
      "b2\n",
      "[[ 0.26633218]\n",
      " [ 0.03688978]\n",
      " [-0.18640447]\n",
      " [ 0.01193619]\n",
      " [ 0.00765649]]\n",
      "W3\n",
      "[[-0.0091582  -0.13360683 -0.38934339 -0.04455239 -0.41520672]\n",
      " [-1.04590731 -0.78085194 -0.33577523 -0.8441504  -0.39156391]\n",
      " [ 0.89368523  0.48350488 -1.05105077 -0.18394774 -0.28123017]\n",
      " [ 0.62337692  0.52670784  1.20812794  0.37648649 -1.08622198]\n",
      " [ 0.36099448 -0.07608951 -0.37241012 -0.66436114  0.3284917 ]]\n",
      "b3\n",
      "[[ 0.00732283]\n",
      " [-0.00760231]\n",
      " [ 0.00261785]\n",
      " [ 0.30740628]\n",
      " [-0.41160196]]\n",
      "W4\n",
      "[[ 1.16247166  0.09467085 -0.22355729 -0.82384675 -1.04744005]\n",
      " [-0.50809095  0.73282432  0.49262883  0.11976416  0.96614603]\n",
      " [ 0.24264674  0.58423576  0.92025983  0.12479286 -0.4425284 ]\n",
      " [-0.44915989  0.37070191  0.03547116  0.97350648 -0.06251059]]\n",
      "b4\n",
      "[[ 1.10477956]\n",
      " [-0.60304571]\n",
      " [-0.71291771]\n",
      " [ 0.21118386]]\n"
     ]
    }
   ],
   "source": [
    "for i in Classifier_model_1.parameters:\n",
    "    print(i)\n",
    "    print(Classifier_model_1.parameters[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
